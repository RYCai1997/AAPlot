{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ã€AAPlot å¤šå›¾ç‰ˆ - ä¼˜åŒ–ç‰ˆã€‘\n",
        "## ç”¨äºå¯¹Spike2è¾“å‡ºçš„txtæ–‡ä»¶ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾\n",
        "\n",
        "### ä¸»è¦æ”¹è¿›ï¼š\n",
        "1. **é…ç½®ç®¡ç†** - æ‰€æœ‰å‚æ•°é›†ä¸­ç®¡ç†ï¼Œä¾¿äºä¿®æ”¹\n",
        "2. **é”™è¯¯å¤„ç†** - å¢åŠ æ–‡ä»¶æ£€æŸ¥å’Œå¼‚å¸¸å¤„ç†\n",
        "3. **é¢œè‰²é…ç½®** - æ”¯æŒå¤šç§é¢œè‰²æ–¹æ¡ˆï¼Œä¾¿äºåˆ‡æ¢\n",
        "4. **è·¯å¾„ç®¡ç†** - æ”¯æŒå¤šç§è·¯å¾„è®¾ç½®æ–¹å¼\n",
        "\n",
        "### æ•°æ®æ ¼å¼è¦æ±‚ï¼š\n",
        "1. è¾“å…¥æ•°æ®ä¸ºSpike2ç›´æ¥è¾“å‡ºçš„Spreadsheetç±»æ–‡ä»¶ï¼Œæ ¼å¼ä¸º.csvæˆ–.txt\n",
        "2. æ–‡ä»¶å†…å®¹åº”ä¸ºä¸‰åˆ—ï¼š\n",
        "   - ç¬¬ä¸€åˆ—ä¸ºæ—¶é—´\n",
        "   - ç¬¬äºŒåˆ—ä¸ºæ•°æ®ç‚¹\n",
        "   - ç¬¬ä¸‰åˆ—ä¸ºè¯ç‰©æ³¨å°„æ—¶é—´æ‰“æ ‡ï¼Œæ•°æ®ä¸­è¯¥è¡Œæ˜¾ç¤ºä¸º1\n",
        "\n",
        "### ç¯å¢ƒè¦æ±‚ï¼š\n",
        "- Python3.12.7\n",
        "- pandas, numpy, matplotlib, seaborn, scipy\n",
        "- ipykernel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step1: é…ç½®å‚æ•°è®¾ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== é…ç½®å‚æ•°åŒºåŸŸ ==========\n",
        "# åœ¨è¿™é‡Œä¿®æ”¹æ‚¨çš„å‚æ•°è®¾ç½®\n",
        "\n",
        "# 1. æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„è®¾ç½®\n",
        "FOLDER_PATH = r'D:\\Science\\Experiment data\\eCB sensors\\Selective sensor\\FiberPhotometry\\Drug intake\\NAcSh_All_data_in_1_folder\\01_Summary\\2-AG\\cocaine'\n",
        "\n",
        "# 2. é¢œè‰²æ–¹æ¡ˆè®¾ç½® (é€‰æ‹©å…¶ä¸­ä¸€ä¸ªæ–¹æ¡ˆ)\n",
        "COLOR_SCHEME = {\n",
        "    # æ–¹æ¡ˆ1: ç»å…¸é…è‰²\n",
        "    'classic': {\n",
        "        'individual': 'lightgrey',\n",
        "        'mean': 'darkgoldenrod',\n",
        "        'error_band': 'darkgoldenrod'\n",
        "    },\n",
        "    # æ–¹æ¡ˆ2: è“è‰²ç³»\n",
        "    'blue': {\n",
        "        'individual': 'lightblue',\n",
        "        'mean': 'steelblue',\n",
        "        'error_band': 'steelblue'\n",
        "    },\n",
        "    # æ–¹æ¡ˆ3: çº¢è‰²ç³»\n",
        "    'red': {\n",
        "        'individual': 'lightcoral',\n",
        "        'mean': 'darkred',\n",
        "        'error_band': 'darkred'\n",
        "    },\n",
        "    # æ–¹æ¡ˆ4: ç»¿è‰²ç³»\n",
        "    'green': {\n",
        "        'individual': 'lightgreen',\n",
        "        'mean': 'darkgreen',\n",
        "        'error_band': 'darkgreen'\n",
        "    },\n",
        "    # æ–¹æ¡ˆ5: ç´«è‰²ç³»\n",
        "    'purple': {\n",
        "        'individual': 'plum',\n",
        "        'mean': 'purple',\n",
        "        'error_band': 'purple'\n",
        "    }\n",
        "}\n",
        "\n",
        "# å½“å‰ä½¿ç”¨çš„é¢œè‰²æ–¹æ¡ˆ (ä¿®æ”¹è¿™é‡Œåˆ‡æ¢é¢œè‰²)\n",
        "CURRENT_COLOR_SCHEME = 'classic'  # å¯é€‰: 'classic', 'blue', 'red', 'green', 'purple'\n",
        "\n",
        "# 3. å›¾è¡¨å‚æ•°è®¾ç½®\n",
        "PLOT_CONFIG = {\n",
        "    'figsize': (8, 3),\n",
        "    'linewidth_individual': 1,\n",
        "    'linewidth_mean': 3,\n",
        "    'linewidth_vertical': 3,\n",
        "    'alpha_error_band': 0.2,\n",
        "    'font_family': 'Arial',\n",
        "    'xlabel_size': 20,\n",
        "    'ylabel_size': 20,\n",
        "    'tick_size': 18\n",
        "}\n",
        "\n",
        "# 4. åæ ‡è½´è®¾ç½®\n",
        "AXIS_CONFIG = {\n",
        "    'x_limits': (-0.25, 1.5),\n",
        "    'y_limits': (-5, 15),\n",
        "    'x_ticks': np.arange(-0.5, 2.1, 0.5),\n",
        "    'y_ticks': np.arange(-5, 15, 5)\n",
        "}\n",
        "\n",
        "# 5. åˆ†æå‚æ•°è®¾ç½®\n",
        "ANALYSIS_CONFIG = {\n",
        "    'smoothing_window': 2001,\n",
        "    'smoothing_polyorder': 2,\n",
        "    'start_time': 300,   # ç§’\n",
        "    'end_time': 2100     # ç§’\n",
        "}\n",
        "\n",
        "# 6. è¾“å‡ºè®¾ç½®\n",
        "OUTPUT_CONFIG = {\n",
        "    'save_plot': True,\n",
        "    'save_metrics': True,\n",
        "    'save_aligned_data': False,\n",
        "    'plot_format': 'svg',\n",
        "    'plot_dpi': 300\n",
        "}\n",
        "\n",
        "# ========== é…ç½®éªŒè¯ ==========\n",
        "def validate_config():\n",
        "    \"\"\"éªŒè¯é…ç½®å‚æ•°\"\"\"\n",
        "    if not os.path.exists(FOLDER_PATH):\n",
        "        print(f\"âš ï¸ è­¦å‘Š: æ–‡ä»¶å¤¹ä¸å­˜åœ¨ - {FOLDER_PATH}\")\n",
        "        return False\n",
        "    \n",
        "    if CURRENT_COLOR_SCHEME not in COLOR_SCHEME:\n",
        "        print(f\"âš ï¸ è­¦å‘Š: æœªçŸ¥çš„é¢œè‰²æ–¹æ¡ˆ - {CURRENT_COLOR_SCHEME}\")\n",
        "        return False\n",
        "    \n",
        "    print(f\"âœ… é…ç½®éªŒè¯é€šè¿‡\")\n",
        "    print(f\"ğŸ“ æ•°æ®æ–‡ä»¶å¤¹: {FOLDER_PATH}\")\n",
        "    print(f\"ğŸ¨ é¢œè‰²æ–¹æ¡ˆ: {CURRENT_COLOR_SCHEME}\")\n",
        "    return True\n",
        "\n",
        "# éªŒè¯é…ç½®\n",
        "validate_config()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step2: å¯¼å…¥å¿…è¦åº“\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦åº“\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import glob\n",
        "import warnings\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "# å¿½ç•¥è­¦å‘Šä¿¡æ¯\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step3: æ•°æ®åŠ è½½å’Œå¤„ç†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== æ•°æ®åŠ è½½å‡½æ•° ==========\n",
        "def load_and_process_data(folder_path):\n",
        "    \"\"\"åŠ è½½å’Œå¤„ç†æ•°æ®æ–‡ä»¶\"\"\"\n",
        "    try:\n",
        "        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨\n",
        "        if not os.path.exists(folder_path):\n",
        "            raise FileNotFoundError(f\"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}\")\n",
        "        \n",
        "        # è·å–æ‰€æœ‰txtæ–‡ä»¶\n",
        "        txt_files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
        "        txt_files.sort()\n",
        "        \n",
        "        if not txt_files:\n",
        "            raise FileNotFoundError(f\"åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ°.txtæ–‡ä»¶\")\n",
        "        \n",
        "        print(f\"ğŸ“ æ‰¾åˆ° {len(txt_files)} ä¸ªæ•°æ®æ–‡ä»¶\")\n",
        "        \n",
        "        # è¯»å–æ‰€æœ‰æ–‡ä»¶\n",
        "        all_data = []\n",
        "        for i, file in enumerate(txt_files):\n",
        "            try:\n",
        "                df = pd.read_csv(file, sep=',')\n",
        "                if df.shape[1] < 3:\n",
        "                    print(f\"âš ï¸ è­¦å‘Š: æ–‡ä»¶ {os.path.basename(file)} åˆ—æ•°ä¸è¶³\")\n",
        "                    continue\n",
        "                all_data.append(df)\n",
        "                print(f\"âœ… åŠ è½½: {os.path.basename(file)} ({len(df)} è¡Œ)\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ é”™è¯¯: æ— æ³•è¯»å– {os.path.basename(file)} - {e}\")\n",
        "        \n",
        "        if not all_data:\n",
        "            raise ValueError(\"æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶\")\n",
        "        \n",
        "        return all_data\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n",
        "        return None\n",
        "\n",
        "# ========== æ•°æ®å¯¹é½å‡½æ•° ==========\n",
        "def align_data_to_events(all_data):\n",
        "    \"\"\"å°†æ•°æ®å¯¹é½åˆ°äº‹ä»¶æ ‡è®°\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸ”„ å¼€å§‹æ•°æ®å¯¹é½...\")\n",
        "        \n",
        "        # é‡ç®—æ¯ä¸ªdataframeä¸­çš„æ—¶é—´ï¼Œä»¥äº‹ä»¶æ ‡è®°ä¸º0ç‚¹\n",
        "        for i, df in enumerate(all_data):\n",
        "            event_mask = df.iloc[:, 2] == 1\n",
        "            if not event_mask.any():\n",
        "                print(f\"âš ï¸ è­¦å‘Š: æ–‡ä»¶ {i} ä¸­æœªæ‰¾åˆ°äº‹ä»¶æ ‡è®°\")\n",
        "                continue\n",
        "            event_time = df.iloc[:, 0][event_mask].iloc[0]\n",
        "            df.iloc[:, 0] = df.iloc[:, 0] - event_time\n",
        "        \n",
        "        # è®¡ç®—æ—¶é—´é—´éš”\n",
        "        dt = all_data[0].iloc[1, 0] - all_data[0].iloc[0, 0]\n",
        "        print(f\"â±ï¸ æ—¶é—´é—´éš”: {dt:.4f} ç§’\")\n",
        "        \n",
        "        # æ‰¾åˆ°æ¯ä¸ªæ–‡ä»¶ä¸­äº‹ä»¶æ ‡è®°çš„ä½ç½®\n",
        "        time_0_indices = []\n",
        "        valid_data = []\n",
        "        \n",
        "        for i, df in enumerate(all_data):\n",
        "            event_mask = df.iloc[:, 2] == 1\n",
        "            if event_mask.any():\n",
        "                time_0_index = df.iloc[:, 0][event_mask].index[0]\n",
        "                time_0_indices.append(time_0_index)\n",
        "                valid_data.append(df)\n",
        "        \n",
        "        if not time_0_indices:\n",
        "            raise ValueError(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„äº‹ä»¶æ ‡è®°\")\n",
        "        \n",
        "        # è®¡ç®—å¯¹é½å‚æ•°\n",
        "        max_pre_len = max(time_0_indices)\n",
        "        max_post_len = max([len(df) - idx for df, idx in zip(valid_data, time_0_indices)])\n",
        "        \n",
        "        print(f\"ğŸ“Š å¯¹é½å‚æ•°: å‰æ®µæœ€å¤§é•¿åº¦={max_pre_len}, åæ®µæœ€å¤§é•¿åº¦={max_post_len}\")\n",
        "        \n",
        "        # å¯¹é½æ•°æ®\n",
        "        all_data_aligned = pd.DataFrame()\n",
        "        \n",
        "        for i, (df, time_0_idx) in enumerate(zip(valid_data, time_0_indices)):\n",
        "            signal = df.iloc[:, 1].values\n",
        "            \n",
        "            # å¯¹é½å‰æ®µæ•°æ®\n",
        "            pre_signal = signal[:time_0_idx]\n",
        "            padded_pre = np.full(max_pre_len, np.nan)\n",
        "            padded_pre[-len(pre_signal):] = pre_signal\n",
        "            \n",
        "            # å¯¹é½åæ®µæ•°æ®\n",
        "            post_signal = signal[time_0_idx:]\n",
        "            padded_post = np.full(max_post_len, np.nan)\n",
        "            padded_post[:len(post_signal)] = post_signal\n",
        "            \n",
        "            # åˆå¹¶ä¿¡å·\n",
        "            aligned_signal = np.concatenate([padded_pre, padded_post])\n",
        "            all_data_aligned[f'signal_{i}'] = aligned_signal\n",
        "        \n",
        "        # åˆ›å»ºæ—¶é—´è½´\n",
        "        total_length = max_pre_len + max_post_len\n",
        "        pre_time = np.linspace(-max_pre_len * dt/3600, 0, max_pre_len, endpoint=False)\n",
        "        post_time = np.linspace(0, max_post_len * dt/3600, max_post_len, endpoint=False)[1:]\n",
        "        time_axis = np.concatenate([pre_time, [0], post_time])\n",
        "        \n",
        "        # åˆ›å»ºæœ€ç»ˆDataFrame\n",
        "        final_df = pd.DataFrame({'Time(h)': time_axis})\n",
        "        \n",
        "        for i, col in enumerate(all_data_aligned.columns):\n",
        "            final_df[col] = pd.to_numeric(all_data_aligned[col], errors='coerce')\n",
        "        \n",
        "        # è®¡ç®—ç»Ÿè®¡é‡\n",
        "        signal_columns = [col for col in final_df.columns if 'signal_' in col]\n",
        "        if signal_columns:\n",
        "            final_df['Mean'] = final_df[signal_columns].mean(axis=1, skipna=True)\n",
        "            final_df['Std'] = final_df[signal_columns].std(axis=1, skipna=True)\n",
        "            n_valid = final_df[signal_columns].count(axis=1)\n",
        "            final_df['StdErr'] = final_df['Std'] / np.sqrt(n_valid)\n",
        "        \n",
        "        print(f\"âœ… æ•°æ®å¯¹é½å®Œæˆ: {len(signal_columns)} ä¸ªä¿¡å·, {len(final_df)} ä¸ªæ—¶é—´ç‚¹\")\n",
        "        return final_df, dt\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ•°æ®å¯¹é½å¤±è´¥: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ========== æ‰§è¡Œæ•°æ®å¤„ç† ==========\n",
        "print(\"ğŸš€ å¼€å§‹æ•°æ®å¤„ç†...\")\n",
        "all_data = load_and_process_data(FOLDER_PATH)\n",
        "\n",
        "if all_data is not None:\n",
        "    final_df, dt = align_data_to_events(all_data)\n",
        "    if final_df is not None:\n",
        "        print(\"âœ… æ•°æ®å¤„ç†å®Œæˆ\")\n",
        "        print(f\"ğŸ“Š æ•°æ®æ‘˜è¦: {final_df.shape[0]} è¡Œ, {final_df.shape[1]} åˆ—\")\n",
        "    else:\n",
        "        print(\"âŒ æ•°æ®å¤„ç†å¤±è´¥\")\n",
        "else:\n",
        "    print(\"âŒ æ•°æ®åŠ è½½å¤±è´¥\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step4: æ•°æ®å¯è§†åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== å¯è§†åŒ–å‡½æ•° ==========\n",
        "def create_plot(final_df, color_scheme, plot_config, axis_config, folder_path):\n",
        "    \"\"\"åˆ›å»ºæ—¶é—´åºåˆ—å›¾\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸ“Š å¼€å§‹åˆ›å»ºå›¾è¡¨...\")\n",
        "        \n",
        "        # è·å–å½“å‰é¢œè‰²æ–¹æ¡ˆ\n",
        "        colors = color_scheme\n",
        "        \n",
        "        # åˆ›å»ºå›¾è¡¨\n",
        "        plt.figure(figsize=plot_config['figsize'])\n",
        "        \n",
        "        # è·å–ä¿¡å·åˆ—\n",
        "        signal_columns = [col for col in final_df.columns if 'signal_' in col]\n",
        "        \n",
        "        # ç»˜åˆ¶ä¸ªä½“ä¿¡å·\n",
        "        for col in signal_columns:\n",
        "            plt.plot(final_df['Time(h)'], final_df[col], \n",
        "                    color=colors['individual'],\n",
        "                    linewidth=plot_config['linewidth_individual'],\n",
        "                    alpha=0.7)\n",
        "        \n",
        "        # ç»˜åˆ¶å‡å€¼æ›²çº¿\n",
        "        if 'Mean' in final_df.columns:\n",
        "            plt.plot(final_df['Time(h)'], final_df['Mean'], \n",
        "                    color=colors['mean'],\n",
        "                    linewidth=plot_config['linewidth_mean'],\n",
        "                    label='Mean')\n",
        "            \n",
        "            # ç»˜åˆ¶è¯¯å·®å¸¦ï¼ˆå¯é€‰ï¼‰\n",
        "            if 'StdErr' in final_df.columns:\n",
        "                plt.fill_between(final_df['Time(h)'],\n",
        "                               final_df['Mean'] - final_df['StdErr'],\n",
        "                               final_df['Mean'] + final_df['StdErr'],\n",
        "                               color=colors['error_band'],\n",
        "                               alpha=plot_config['alpha_error_band'])\n",
        "        \n",
        "        # è®¾ç½®å­—ä½“\n",
        "        plt.rcParams['font.sans-serif'] = [plot_config['font_family']]\n",
        "        \n",
        "        # è®¾ç½®æ ‡ç­¾\n",
        "        plt.xlabel('Time (h)', fontsize=plot_config['xlabel_size'])\n",
        "        plt.ylabel('z-score', fontsize=plot_config['ylabel_size'])\n",
        "        \n",
        "        # è®¾ç½®åˆ»åº¦\n",
        "        plt.xticks(axis_config['x_ticks'], fontsize=plot_config['tick_size'])\n",
        "        plt.yticks(axis_config['y_ticks'], fontsize=plot_config['tick_size'])\n",
        "        \n",
        "        # è®¾ç½®è½´èŒƒå›´\n",
        "        plt.xlim(axis_config['x_limits'])\n",
        "        plt.ylim(axis_config['y_limits'])\n",
        "        \n",
        "        # æ·»åŠ äº‹ä»¶çº¿\n",
        "        plt.axvline(0, color='black', linestyle='--', \n",
        "                   linewidth=plot_config['linewidth_vertical'])\n",
        "        \n",
        "        # è®¾ç½®é€æ˜èƒŒæ™¯\n",
        "        plt.gcf().patch.set_alpha(0.0)\n",
        "        plt.gca().patch.set_alpha(0.0)\n",
        "        sns.despine()\n",
        "        \n",
        "        # ä¿å­˜å›¾è¡¨\n",
        "        if OUTPUT_CONFIG['save_plot']:\n",
        "            output_fig = os.path.join(folder_path, f'plot_{CURRENT_COLOR_SCHEME}.{OUTPUT_CONFIG[\"plot_format\"]}')\n",
        "            plt.savefig(output_fig, format=OUTPUT_CONFIG['plot_format'], \n",
        "                       bbox_inches='tight', dpi=OUTPUT_CONFIG['plot_dpi'])\n",
        "            print(f\"âœ… å›¾è¡¨å·²ä¿å­˜: {output_fig}\")\n",
        "        \n",
        "        plt.show()\n",
        "        print(\"âœ… å›¾è¡¨åˆ›å»ºå®Œæˆ\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å›¾è¡¨åˆ›å»ºå¤±è´¥: {e}\")\n",
        "\n",
        "# ========== æ‰§è¡Œå¯è§†åŒ– ==========\n",
        "if 'final_df' in locals() and final_df is not None:\n",
        "    # è·å–å½“å‰é¢œè‰²æ–¹æ¡ˆ\n",
        "    current_colors = COLOR_SCHEME[CURRENT_COLOR_SCHEME]\n",
        "    \n",
        "    # åˆ›å»ºå›¾è¡¨\n",
        "    create_plot(final_df, current_colors, PLOT_CONFIG, AXIS_CONFIG, FOLDER_PATH)\n",
        "else:\n",
        "    print(\"âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®ç”¨äºç»˜å›¾\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step5: æ•°æ®åˆ†æ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== æ•°æ®å¹³æ»‘å‡½æ•° ==========\n",
        "def smooth_data(df, window_length=2001, polyorder=2):\n",
        "    \"\"\"å¯¹æ•°æ®è¿›è¡Œå¹³æ»‘å¤„ç†\"\"\"\n",
        "    try:\n",
        "        smoothed_df = df.copy()\n",
        "        signal_columns = [col for col in df.columns if 'signal_' in col]\n",
        "        \n",
        "        for col in signal_columns:\n",
        "            # ç§»é™¤NaNå€¼è¿›è¡Œå¹³æ»‘\n",
        "            valid_mask = ~pd.isna(smoothed_df[col])\n",
        "            if valid_mask.sum() > window_length:\n",
        "                smoothed_values = savgol_filter(\n",
        "                    smoothed_df.loc[valid_mask, col].values,\n",
        "                    window_length, polyorder, mode='nearest'\n",
        "                )\n",
        "                smoothed_df.loc[valid_mask, col] = smoothed_values\n",
        "        \n",
        "        print(f\"âœ… æ•°æ®å¹³æ»‘å®Œæˆ (çª—å£={window_length}, é˜¶æ•°={polyorder})\")\n",
        "        return smoothed_df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ•°æ®å¹³æ»‘å¤±è´¥: {e}\")\n",
        "        return df\n",
        "\n",
        "# ========== æŒ‡æ ‡è®¡ç®—å‡½æ•° ==========\n",
        "def calculate_metrics(df, start_time=300, end_time=2100):\n",
        "    \"\"\"è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡\"\"\"\n",
        "    try:\n",
        "        signal_columns = [col for col in df.columns if 'signal_' in col]\n",
        "        metrics = {}\n",
        "        \n",
        "        # åˆ›å»ºæ—¶é—´æ©ç \n",
        "        time_mask = ((df['Time(h)'] >= start_time / 3600) & \n",
        "                    (df['Time(h)'] <= end_time / 3600))\n",
        "        \n",
        "        for col in signal_columns:\n",
        "            filtered_data = df.loc[time_mask, col].dropna()\n",
        "            \n",
        "            if len(filtered_data) > 0:\n",
        "                # è®¡ç®—æœ€å¤§å€¼ã€æœ€å°å€¼\n",
        "                max_val = filtered_data.max()\n",
        "                min_val = filtered_data.min()\n",
        "                \n",
        "                # è®¡ç®—æ›²çº¿ä¸‹é¢ç§¯ (AUC)\n",
        "                time_points = df.loc[time_mask, 'Time(h)'].values\n",
        "                valid_time_mask = ~pd.isna(df.loc[time_mask, col])\n",
        "                \n",
        "                if valid_time_mask.sum() > 1:\n",
        "                    valid_time = time_points[valid_time_mask]\n",
        "                    valid_data = filtered_data.values\n",
        "                    auc = np.trapz(valid_data, valid_time)\n",
        "                else:\n",
        "                    auc = np.nan\n",
        "                \n",
        "                metrics[col] = {\n",
        "                    'max': max_val,\n",
        "                    'min': min_val,\n",
        "                    'area': auc\n",
        "                }\n",
        "            else:\n",
        "                metrics[col] = {'max': np.nan, 'min': np.nan, 'area': np.nan}\n",
        "        \n",
        "        metrics_df = pd.DataFrame(metrics).T\n",
        "        print(f\"âœ… æŒ‡æ ‡è®¡ç®—å®Œæˆ: {len(metrics_df)} ä¸ªä¿¡å·\")\n",
        "        return metrics_df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ========== æ‰§è¡Œæ•°æ®åˆ†æ ==========\n",
        "if 'final_df' in locals() and final_df is not None:\n",
        "    print(\"ğŸ”¬ å¼€å§‹æ•°æ®åˆ†æ...\")\n",
        "    \n",
        "    # æ•°æ®å¹³æ»‘\n",
        "    smoothed_df = smooth_data(final_df, \n",
        "                              ANALYSIS_CONFIG['smoothing_window'], \n",
        "                              ANALYSIS_CONFIG['smoothing_polyorder'])\n",
        "    \n",
        "    # è®¡ç®—æŒ‡æ ‡\n",
        "    metrics_df = calculate_metrics(smoothed_df, \n",
        "                                   ANALYSIS_CONFIG['start_time'], \n",
        "                                   ANALYSIS_CONFIG['end_time'])\n",
        "    \n",
        "    # ä¿å­˜æŒ‡æ ‡\n",
        "    if OUTPUT_CONFIG['save_metrics'] and not metrics_df.empty:\n",
        "        output_metrics = os.path.join(FOLDER_PATH, f'metrics_{CURRENT_COLOR_SCHEME}.csv')\n",
        "        metrics_df.to_csv(output_metrics, index=True)\n",
        "        print(f\"âœ… æŒ‡æ ‡å·²ä¿å­˜: {output_metrics}\")\n",
        "    \n",
        "    # ä¿å­˜å¯¹é½æ•°æ®ï¼ˆå¯é€‰ï¼‰\n",
        "    if OUTPUT_CONFIG['save_aligned_data']:\n",
        "        output_data = os.path.join(FOLDER_PATH, f'aligned_data_{CURRENT_COLOR_SCHEME}.csv')\n",
        "        final_df.to_csv(output_data, index=False)\n",
        "        print(f\"âœ… å¯¹é½æ•°æ®å·²ä¿å­˜: {output_data}\")\n",
        "    \n",
        "    # æ˜¾ç¤ºç»“æœ\n",
        "    print(\"\\nğŸ“Š ç»Ÿè®¡æŒ‡æ ‡:\")\n",
        "    print(metrics_df)\n",
        "    \n",
        "    # æ˜¾ç¤ºæ•°æ®æ‘˜è¦\n",
        "    print(f\"\\nğŸ“‹ æ•°æ®æ‘˜è¦:\")\n",
        "    print(f\"   ä¿¡å·æ•°é‡: {len([col for col in final_df.columns if 'signal_' in col])}\")\n",
        "    print(f\"   æ—¶é—´èŒƒå›´: {final_df['Time(h)'].min():.3f} - {final_df['Time(h)'].max():.3f} å°æ—¶\")\n",
        "    print(f\"   æ•°æ®ç‚¹æ•°: {len(final_df)}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®ç”¨äºåˆ†æ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä½¿ç”¨è¯´æ˜\n",
        "\n",
        "### ğŸ¨ å¦‚ä½•åˆ‡æ¢é¢œè‰²æ–¹æ¡ˆï¼š\n",
        "1. åœ¨ **Step1** ä¸­æ‰¾åˆ° `CURRENT_COLOR_SCHEME` å˜é‡\n",
        "2. å°†å…¶ä¿®æ”¹ä¸ºä»¥ä¸‹é€‰é¡¹ä¹‹ä¸€ï¼š\n",
        "   - `'classic'` - ç»å…¸é…è‰²ï¼ˆç°è‰²+é‡‘è‰²ï¼‰\n",
        "   - `'blue'` - è“è‰²ç³»\n",
        "   - `'red'` - çº¢è‰²ç³»\n",
        "   - `'green'` - ç»¿è‰²ç³»\n",
        "   - `'purple'` - ç´«è‰²ç³»\n",
        "3. é‡æ–°è¿è¡Œ **Step4** (æ•°æ®å¯è§†åŒ–)\n",
        "\n",
        "### ğŸ“ å¦‚ä½•æ›´æ¢æ•°æ®æ–‡ä»¶å¤¹ï¼š\n",
        "1. åœ¨ **Step1** ä¸­æ‰¾åˆ° `FOLDER_PATH` å˜é‡\n",
        "2. ä¿®æ”¹ä¸ºæ‚¨çš„å®é™…æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„\n",
        "3. é‡æ–°è¿è¡Œ **Step3** (æ•°æ®åŠ è½½å’Œå¤„ç†)\n",
        "\n",
        "### âš™ï¸ å…¶ä»–å‚æ•°è°ƒæ•´ï¼š\n",
        "- **å›¾è¡¨å‚æ•°**: ä¿®æ”¹ `PLOT_CONFIG` ä¸­çš„è®¾ç½®\n",
        "- **åæ ‡è½´**: ä¿®æ”¹ `AXIS_CONFIG` ä¸­çš„èŒƒå›´\n",
        "- **åˆ†æå‚æ•°**: ä¿®æ”¹ `ANALYSIS_CONFIG` ä¸­çš„æ—¶é—´çª—å£\n",
        "- **è¾“å‡ºè®¾ç½®**: ä¿®æ”¹ `OUTPUT_CONFIG` ä¸­çš„ä¿å­˜é€‰é¡¹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
