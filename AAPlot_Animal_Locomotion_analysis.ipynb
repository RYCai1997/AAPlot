{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c976d0",
   "metadata": {},
   "source": [
    "# 【AAPlot for Animal Behavior (Analyze)】\n",
    "## Extract speed and trajectory of **Spike2** exported .txt file\n",
    "\n",
    "This notebook analyzes animal movement data before and after specific events, including:\n",
    "- Data cleaning (removal of artifacts)\n",
    "- Time rescaling around events\n",
    "- Speed analysis in different time windows\n",
    "- Distance calculations\n",
    "- Statistical analysis and data export\n",
    "\n",
    "\n",
    "Run under `PLOT` environment\n",
    "    \n",
    "The `PLOT` enviorment：\n",
    "- Python3.12.7\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- ipykernel\n",
    "\n",
    "*Warning*\n",
    "\n",
    "*! Make sure you have installed `Anaconda`，and added to PATH（refering to internet）*\n",
    "\n",
    "*! Make sure you have already confiured the `PLOT` environment, if not, run this command: `conda env create -n PLOT python=3.12.7 pandas numpy matplotlib seaborn ipykernel` (If you are using ARM64 CPU, use Python3.13.3 intead，add `conda-forge` at the end of command)*\n",
    "\n",
    "*Apply `PLOT` in VScode ：Select in the Kernel*\n",
    "\n",
    "*Apply `PLOT` in terminal：`conda activate PLOT`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54d59c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "730c4829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\RuyiCai\\AppData\\Local\\Temp\\ipykernel_22132\\1332192203.py:20: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for separator in ['\\t', ',', '\\s+']:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of the file:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,12.39,0\n",
      "0.1,10.70,0\n",
      "0.2,9.42,0\n",
      "0.3,8.57,0\n",
      "\n",
      "Successfully read file with ',' separator\n",
      "\n",
      "Initial data shape: (417008, 3)\n",
      "Sample of raw data:\n",
      "     0      1  2\n",
      "0  0.0  12.39  0\n",
      "1  0.1  10.70  0\n",
      "2  0.2   9.42  0\n",
      "3  0.3   8.57  0\n",
      "4  0.4   8.12  0\n",
      "\n",
      "Final data structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417008 entries, 0 to 417007\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    417008 non-null  float64\n",
      " 1   Speed   417008 non-null  float64\n",
      " 2   Marker  417008 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.5 MB\n",
      "None\n",
      "\n",
      "Sample of processed data:\n",
      "   Time  Speed  Marker\n",
      "0   0.0  12.39       0\n",
      "1   0.1  10.70       0\n",
      "2   0.2   9.42       0\n",
      "3   0.3   8.57       0\n",
      "4   0.4   8.12       0\n",
      "\n",
      "Successfully read file with ',' separator\n",
      "\n",
      "Initial data shape: (417008, 3)\n",
      "Sample of raw data:\n",
      "     0      1  2\n",
      "0  0.0  12.39  0\n",
      "1  0.1  10.70  0\n",
      "2  0.2   9.42  0\n",
      "3  0.3   8.57  0\n",
      "4  0.4   8.12  0\n",
      "\n",
      "Final data structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417008 entries, 0 to 417007\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    417008 non-null  float64\n",
      " 1   Speed   417008 non-null  float64\n",
      " 2   Marker  417008 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.5 MB\n",
      "None\n",
      "\n",
      "Sample of processed data:\n",
      "   Time  Speed  Marker\n",
      "0   0.0  12.39       0\n",
      "1   0.1  10.70       0\n",
      "2   0.2   9.42       0\n",
      "3   0.3   8.57       0\n",
      "4   0.4   8.12       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# File selection\n",
    "Filename = r'D:\\Temp\\DrugIntake behavior\\THC\\male\\C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt'\n",
    "\n",
    "# First, let's look at the file structure\n",
    "with open(Filename, 'r') as file:\n",
    "    first_few_lines = [next(file) for _ in range(5)]\n",
    "print(\"First few lines of the file:\")\n",
    "for line in first_few_lines:\n",
    "    print(line.strip())\n",
    "\n",
    "# Read file with no header, using numbered columns\n",
    "try:\n",
    "    # Try reading with different separators, skip the first row that contains titles\n",
    "    for separator in ['\\t', ',', '\\s+']:\n",
    "        try:\n",
    "            df = pd.read_csv(Filename, sep=separator, header=None, skiprows=1)\n",
    "            if len(df.columns) >= 2:  # We need at least time and speed columns\n",
    "                print(f\"\\nSuccessfully read file with '{separator}' separator\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"\\nInitial data shape:\", df.shape)\n",
    "    print(\"Sample of raw data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Convert time column to numeric\n",
    "    df.iloc[:, 0] = pd.to_numeric(df.iloc[:, 0], errors='coerce')\n",
    "    \n",
    "    # Rename columns by position\n",
    "    if len(df.columns) >= 3:\n",
    "        df = df.iloc[:, :3]  # Take only first three columns if there are more\n",
    "        df.columns = ['Time', 'Speed', 'Marker']\n",
    "    elif len(df.columns) == 2:\n",
    "        df = df.iloc[:, :2]  # Take only first two columns\n",
    "        df.columns = ['Time', 'Speed']\n",
    "        # Add marker column with default event at middle point\n",
    "        df['Marker'] = 0\n",
    "        middle_idx = len(df) // 2\n",
    "        df.loc[middle_idx, 'Marker'] = 1\n",
    "        print(\"\\nNo marker column found. Added marker at middle point.\")\n",
    "    else:\n",
    "        raise ValueError(\"File must have at least 2 columns (Time and Speed)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nFinal data structure:\")\n",
    "print(df.info())\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad02c",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1f0aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (417008, 3)\n",
      "\n",
      "Initial speed statistics:\n",
      "count    417008.000000\n",
      "mean          6.617100\n",
      "std           8.006922\n",
      "min         -31.820000\n",
      "25%           2.830000\n",
      "50%           5.160000\n",
      "75%           8.300000\n",
      "max         588.160000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Number of artifacts removed (speed > 100 cm/s): 186\n",
      "\n",
      "Speed statistics after removing artifacts:\n",
      "count    416822.000000\n",
      "mean          6.509506\n",
      "std           5.751905\n",
      "min         -31.820000\n",
      "25%           2.830000\n",
      "50%           5.160000\n",
      "75%           8.300000\n",
      "max          98.950000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Speed statistics after interpolation:\n",
      "count    417008.000000\n",
      "mean          6.539925\n",
      "std           5.943909\n",
      "min         -31.820000\n",
      "25%           2.830000\n",
      "50%           5.160000\n",
      "75%           8.300000\n",
      "max          98.950000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Number of events found: 1\n",
      "Event time points: [7109.1]\n",
      "\n",
      "Speed distribution percentiles:\n",
      "5th percentile: 0.90 cm/s\n",
      "25th percentile: 2.83 cm/s\n",
      "50th percentile: 5.16 cm/s\n",
      "75th percentile: 8.30 cm/s\n",
      "95th percentile: 17.21 cm/s\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "print(\"Original data shape:\", df.shape)\n",
    "\n",
    "# Convert speed column to numeric, handling any non-numeric values\n",
    "df_cleaned = df.copy()\n",
    "# Speed is always in column 1 (second column)\n",
    "df_cleaned.iloc[:, 1] = pd.to_numeric(df_cleaned.iloc[:, 1], errors='coerce')\n",
    "print(\"\\nInitial speed statistics:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Remove speed artifacts (>100 cm/s)\n",
    "artifacts_mask = df_cleaned.iloc[:, 1] > 100\n",
    "n_artifacts = artifacts_mask.sum()\n",
    "df_cleaned.iloc[artifacts_mask, 1] = np.nan  # Replace artifacts with NaN\n",
    "print(f\"\\nNumber of artifacts removed (speed > 100 cm/s): {n_artifacts}\")\n",
    "print(\"\\nSpeed statistics after removing artifacts:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Interpolate NaN values\n",
    "df_cleaned.iloc[:, 1] = df_cleaned.iloc[:, 1].interpolate(method='linear')\n",
    "print(\"\\nSpeed statistics after interpolation:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Verify event markers (using position-based indexing for consistency)\n",
    "event_times = df_cleaned[df_cleaned.iloc[:, 2] == 1].iloc[:, 0]  # Column 2 is Marker, Column 0 is Time\n",
    "print(f\"\\nNumber of events found: {len(event_times)}\")\n",
    "print(\"Event time points:\", event_times.values)\n",
    "\n",
    "# Calculate percentiles for speed distribution\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "speed_percentiles = np.percentile(df_cleaned.iloc[:, 1].dropna(), percentiles)\n",
    "print(\"\\nSpeed distribution percentiles:\")\n",
    "for p, v in zip(percentiles, speed_percentiles):\n",
    "    print(f\"{p}th percentile: {v:.2f} cm/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25551c",
   "metadata": {},
   "source": [
    "## 3. Time Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea33eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found event marker at time: 7109.10 seconds\n",
      "\n",
      "Time range in dataset:\n",
      "Start: -1.97 hours\n",
      "End: 9.61 hours\n",
      "Total duration: 11.58 hours\n",
      "\n",
      "Data coverage in time windows:\n",
      "pre_1h: 35999 data points\n",
      "post_1h: 36000 data points\n",
      "post_2h: 36000 data points\n",
      "post_3h: 36001 data points\n"
     ]
    }
   ],
   "source": [
    "# Find the event time\n",
    "try:\n",
    "    # Using position-based indexing for consistency\n",
    "    event_markers = df_cleaned[df_cleaned.iloc[:, 2] == 1]\n",
    "    if len(event_markers) > 0:\n",
    "        event_time = event_markers.iloc[0, 0]  # Get time from first event marker\n",
    "        print(f\"Found event marker at time: {event_time:.2f} seconds\")\n",
    "    else:\n",
    "        # If no event markers found, use middle of the time range\n",
    "        time_min = df_cleaned.iloc[:, 0].min()\n",
    "        time_max = df_cleaned.iloc[:, 0].max()\n",
    "        event_time = (time_max + time_min) / 2\n",
    "        print(f\"No event markers found. Using middle point as event time: {event_time:.2f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Error finding event time: {str(e)}\")\n",
    "    # Default to middle of time range\n",
    "    time_min = df_cleaned.iloc[:, 0].min()\n",
    "    time_max = df_cleaned.iloc[:, 0].max()\n",
    "    event_time = (time_max + time_min) / 2\n",
    "    print(f\"Using middle point as event time: {event_time:.2f} seconds\")\n",
    "\n",
    "# Rescale time relative to event (in hours)\n",
    "df_cleaned['Time_hours'] = (df_cleaned.iloc[:, 0] - event_time) / 3600  # Convert to hours\n",
    "\n",
    "# Create time windows for analysis\n",
    "time_windows = {\n",
    "    'pre_1h': (-1, 0),\n",
    "    'post_1h': (0, 1),\n",
    "    'post_2h': (1, 2),\n",
    "    'post_3h': (2, 3)\n",
    "}\n",
    "\n",
    "# Print time range information\n",
    "print(\"\\nTime range in dataset:\")\n",
    "print(f\"Start: {df_cleaned['Time_hours'].min():.2f} hours\")\n",
    "print(f\"End: {df_cleaned['Time_hours'].max():.2f} hours\")\n",
    "print(f\"Total duration: {df_cleaned['Time_hours'].max() - df_cleaned['Time_hours'].min():.2f} hours\")\n",
    "\n",
    "# Print data points in each window\n",
    "print(\"\\nData coverage in time windows:\")\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    window_data = df_cleaned[(df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)]\n",
    "    print(f\"{window_name}: {len(window_data)} data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc2ec7",
   "metadata": {},
   "source": [
    "## 4. Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78263f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed Analysis Results:\n",
      "\n",
      "pre_1h:\n",
      "Mean Speed: 7.32 cm/s\n",
      "Std Dev: 5.14 cm/s\n",
      "Data Points: 35999\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_1h:\n",
      "Mean Speed: 7.35 cm/s\n",
      "Std Dev: 4.96 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_2h:\n",
      "Mean Speed: 7.36 cm/s\n",
      "Std Dev: 5.39 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_3h:\n",
      "Mean Speed: 7.68 cm/s\n",
      "Std Dev: 6.17 cm/s\n",
      "Data Points: 36001\n",
      "Data Completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate average speeds for each time window\n",
    "speed_results = {}\n",
    "data_completeness = {}\n",
    "\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "    window_data = df_cleaned[mask]\n",
    "    \n",
    "    if len(window_data) > 0:\n",
    "        speed_results[window_name] = {\n",
    "            'mean_speed': window_data['Speed'].mean(),\n",
    "            'std_speed': window_data['Speed'].std(),\n",
    "            'n_points': len(window_data)\n",
    "        }\n",
    "        # Calculate data completeness (percentage of the full hour covered)\n",
    "        time_coverage = (window_data['Time_hours'].max() - window_data['Time_hours'].min()) * 60  # in minutes\n",
    "        data_completeness[window_name] = min(100, (time_coverage / 60) * 100)  # as percentage of an hour\n",
    "    else:\n",
    "        speed_results[window_name] = {\n",
    "            'mean_speed': np.nan,\n",
    "            'std_speed': np.nan,\n",
    "            'n_points': 0\n",
    "        }\n",
    "        data_completeness[window_name] = 0\n",
    "\n",
    "# Print results\n",
    "print(\"Speed Analysis Results:\")\n",
    "for window, results in speed_results.items():\n",
    "    print(f\"\\n{window}:\")\n",
    "    print(f\"Mean Speed: {results['mean_speed']:.2f} cm/s\")\n",
    "    print(f\"Std Dev: {results['std_speed']:.2f} cm/s\")\n",
    "    print(f\"Data Points: {results['n_points']}\")\n",
    "    print(f\"Data Completeness: {data_completeness[window]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe225a",
   "metadata": {},
   "source": [
    "## 5. Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59934bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Analysis Results:\n",
      "\n",
      "pre_1h:\n",
      "Distance: 263.35 meters\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_1h:\n",
      "Distance: 264.55 meters\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_2h:\n",
      "Distance: 265.00 meters\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_3h:\n",
      "Distance: 276.48 meters\n",
      "Data Completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate distances for each time window\n",
    "distance_results = {}\n",
    "\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "    window_data = df_cleaned[mask]\n",
    "    \n",
    "    if len(window_data) > 0:\n",
    "        # Calculate distance by integrating speed over time\n",
    "        # Convert speed from cm/s to cm/h and time differences to hours\n",
    "        speeds_cmh = window_data['Speed'] * 3600  # convert to cm/h\n",
    "        time_diff_h = np.diff(window_data['Time_hours'])\n",
    "        speeds_for_calc = speeds_cmh[:-1]  # use speeds except last point\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = np.sum(speeds_for_calc * time_diff_h)\n",
    "        \n",
    "        distance_results[window_name] = {\n",
    "            'distance_cm': distance,\n",
    "            'distance_m': distance / 100,  # convert to meters\n",
    "            'completeness': data_completeness[window]\n",
    "        }\n",
    "    else:\n",
    "        distance_results[window_name] = {\n",
    "            'distance_cm': np.nan,\n",
    "            'distance_m': np.nan,\n",
    "            'completeness': 0\n",
    "        }\n",
    "\n",
    "# Print results\n",
    "print(\"Distance Analysis Results:\")\n",
    "for window, results in distance_results.items():\n",
    "    print(f\"\\n{window}:\")\n",
    "    print(f\"Distance: {results['distance_m']:.2f} meters\")\n",
    "    print(f\"Data Completeness: {results['completeness']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d502fcc",
   "metadata": {},
   "source": [
    "## 6. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6071ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis exported to:\n",
      "1. Raw Data: D:\\Temp\\DrugIntake behavior\\THC\\male\\C16_THC_0_1mpk_LocationOutput_TimeOverSpeed_data.csv\n",
      "2. Summary: D:\\Temp\\DrugIntake behavior\\THC\\male\\C16_THC_0_1mpk_LocationOutput_TimeOverSpeed_summary.csv\n",
      "\n",
      "Analysis Summary:\n",
      "                     Metric      Value  Completeness_%\n",
      "     Total Duration (hours)  11.583528      100.000000\n",
      " Pre-event Duration (hours)   1.974750      100.000000\n",
      "Post-event Duration (hours)   9.608778      100.000000\n",
      " Mean Speed - Pre 1h (cm/s)   7.315757       99.994444\n",
      "Mean Speed - Post 1h (cm/s)   7.348808       99.997222\n",
      "Mean Speed - Post 2h (cm/s)   7.361364       99.997222\n",
      "Mean Speed - Post 3h (cm/s)   7.679872      100.000000\n",
      "      Distance - Pre 1h (m) 263.350475       99.994444\n",
      "     Distance - Post 1h (m) 264.547630       99.997222\n",
      "     Distance - Post 2h (m) 264.998260       99.997222\n",
      "     Distance - Post 3h (m) 276.478620      100.000000\n"
     ]
    }
   ],
   "source": [
    "# Create summary DataFrame\n",
    "combined_summary = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Duration (hours)',\n",
    "        'Pre-event Duration (hours)',\n",
    "        'Post-event Duration (hours)',\n",
    "        'Mean Speed - Pre 1h (cm/s)',\n",
    "        'Mean Speed - Post 1h (cm/s)',\n",
    "        'Mean Speed - Post 2h (cm/s)',\n",
    "        'Mean Speed - Post 3h (cm/s)',\n",
    "        'Distance - Pre 1h (m)',\n",
    "        'Distance - Post 1h (m)',\n",
    "        'Distance - Post 2h (m)',\n",
    "        'Distance - Post 3h (m)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        df_cleaned['Time_hours'].max() - df_cleaned['Time_hours'].min(),\n",
    "        abs(df_cleaned['Time_hours'].min()),\n",
    "        df_cleaned['Time_hours'].max(),\n",
    "        speed_results['pre_1h']['mean_speed'],\n",
    "        speed_results['post_1h']['mean_speed'],\n",
    "        speed_results['post_2h']['mean_speed'],\n",
    "        speed_results['post_3h']['mean_speed'],\n",
    "        distance_results['pre_1h']['distance_m'],\n",
    "        distance_results['post_1h']['distance_m'],\n",
    "        distance_results['post_2h']['distance_m'],\n",
    "        distance_results['post_3h']['distance_m']\n",
    "    ],\n",
    "    'Completeness_%': [\n",
    "        100,\n",
    "        100 if abs(df_cleaned['Time_hours'].min()) >= 1 else abs(df_cleaned['Time_hours'].min()) * 100,\n",
    "        100,\n",
    "        data_completeness['pre_1h'],\n",
    "        data_completeness['post_1h'],\n",
    "        data_completeness['post_2h'],\n",
    "        data_completeness['post_3h'],\n",
    "        data_completeness['pre_1h'],\n",
    "        data_completeness['post_1h'],\n",
    "        data_completeness['post_2h'],\n",
    "        data_completeness['post_3h']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Prepare file paths\n",
    "base_name = os.path.splitext(os.path.basename(Filename))[0]\n",
    "output_dir = os.path.dirname(Filename)\n",
    "data_csv = os.path.join(output_dir, f\"{base_name}_data.csv\")\n",
    "summary_csv = os.path.join(output_dir, f\"{base_name}_summary.csv\")\n",
    "\n",
    "try:\n",
    "    # Export the cleaned data\n",
    "    df_cleaned.to_csv(data_csv, index=False)\n",
    "    # Export the summary\n",
    "    combined_summary.to_csv(summary_csv, index=False)\n",
    "    \n",
    "    print(f\"\\nAnalysis exported to:\")\n",
    "    print(f\"1. Raw Data: {data_csv}\")\n",
    "    print(f\"2. Summary: {summary_csv}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError exporting CSV files: {str(e)}\")\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(combined_summary.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
