{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c976d0",
   "metadata": {},
   "source": [
    "# 【AAPlot for Animal Behavior (Analyze)】\n",
    "## Extract speed and trajectory of **Spike2** exported .txt file\n",
    "\n",
    "This notebook analyzes animal movement data before and after specific events, including:\n",
    "- Data cleaning (removal of artifacts)\n",
    "- Time rescaling around events\n",
    "- Speed analysis in different time windows\n",
    "- Distance calculations\n",
    "- Statistical analysis and data export\n",
    "\n",
    "\n",
    "Run under `PLOT` environment\n",
    "    \n",
    "The `PLOT` enviorment：\n",
    "- Python3.12.7\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- ipykernel\n",
    "\n",
    "*Warning*\n",
    "\n",
    "*! Make sure you have installed `Anaconda`，and added to PATH（refering to internet）*\n",
    "\n",
    "*! Make sure you have already confiured the `PLOT` environment, if not, run this command: `conda env create -n PLOT python=3.12.7 pandas numpy matplotlib seaborn ipykernel` (If you are using ARM64 CPU, use Python3.13.3 intead，add `conda-forge` at the end of command)*\n",
    "\n",
    "*Apply `PLOT` in VScode ：Select in the Kernel*\n",
    "\n",
    "*Apply `PLOT` in terminal：`conda activate PLOT`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54d59c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "730c4829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\RuyiCai\\AppData\\Local\\Temp\\ipykernel_22132\\2462157745.py:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for separator in ['\\t', ',', '\\s+']:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 data files:\n",
      "- C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "- C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "- C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,12.39,0\n",
      "0.1,10.70,0\n",
      "0.2,9.42,0\n",
      "0.3,8.57,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (417008, 3)\n",
      "\n",
      "Example file structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417008 entries, 0 to 417007\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    417008 non-null  float64\n",
      " 1   Speed   417008 non-null  float64\n",
      " 2   Marker  417008 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.5 MB\n",
      "None\n",
      "\n",
      "Sample of processed data:\n",
      "   Time  Speed  Marker\n",
      "0   0.0  12.39       0\n",
      "1   0.1  10.70       0\n",
      "2   0.2   9.42       0\n",
      "3   0.3   8.57       0\n",
      "4   0.4   8.12       0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (417008, 3)\n",
      "\n",
      "Example file structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417008 entries, 0 to 417007\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    417008 non-null  float64\n",
      " 1   Speed   417008 non-null  float64\n",
      " 2   Marker  417008 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.5 MB\n",
      "None\n",
      "\n",
      "Sample of processed data:\n",
      "   Time  Speed  Marker\n",
      "0   0.0  12.39       0\n",
      "1   0.1  10.70       0\n",
      "2   0.2   9.42       0\n",
      "3   0.3   8.57       0\n",
      "4   0.4   8.12       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import stats\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder selection - replace with your folder path\n",
    "folder_path = r'D:\\Temp\\DrugIntake behavior\\THC\\male\\test'\n",
    "\n",
    "# Find all CSV and TXT files in the folder\n",
    "data_files = []\n",
    "for ext in ['.txt', '.csv']:\n",
    "    data_files.extend(glob.glob(os.path.join(folder_path, f'*{ext}')))\n",
    "\n",
    "if not data_files:\n",
    "    print(f\"No .txt or .csv files found in {folder_path}\")\n",
    "    raise ValueError(\"No data files found\")\n",
    "\n",
    "print(f\"Found {len(data_files)} data files:\")\n",
    "for file in data_files:\n",
    "    print(f\"- {os.path.basename(file)}\")\n",
    "\n",
    "# Function to read and preprocess a single file\n",
    "def read_data_file(filepath):\n",
    "    # First, look at the file structure\n",
    "    with open(filepath, 'r') as file:\n",
    "        first_few_lines = [next(file) for _ in range(5)]\n",
    "    print(f\"\\nReading file: {os.path.basename(filepath)}\")\n",
    "    print(\"First few lines:\")\n",
    "    for line in first_few_lines:\n",
    "        print(line.strip())\n",
    "    \n",
    "    # Try reading with different separators\n",
    "    for separator in ['\\t', ',', '\\s+']:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=separator, header=None, skiprows=1)\n",
    "            if len(df.columns) >= 2:  # We need at least time and speed columns\n",
    "                print(f\"Successfully read file with '{separator}' separator\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        raise ValueError(f\"Could not read file {filepath} with any known separator\")\n",
    "\n",
    "    print(\"Initial data shape:\", df.shape)\n",
    "    \n",
    "    # Convert time column to numeric\n",
    "    df.iloc[:, 0] = pd.to_numeric(df.iloc[:, 0], errors='coerce')\n",
    "    \n",
    "    # Rename columns by position\n",
    "    if len(df.columns) >= 3:\n",
    "        df = df.iloc[:, :3]  # Take only first three columns\n",
    "        df.columns = ['Time', 'Speed', 'Marker']\n",
    "    elif len(df.columns) == 2:\n",
    "        df = df.iloc[:, :2]  # Take only first two columns\n",
    "        df.columns = ['Time', 'Speed']\n",
    "        # Add marker column with default event at middle point\n",
    "        df['Marker'] = 0\n",
    "        middle_idx = len(df) // 2\n",
    "        df.loc[middle_idx, 'Marker'] = 1\n",
    "        print(\"No marker column found. Added marker at middle point.\")\n",
    "    else:\n",
    "        raise ValueError(\"File must have at least 2 columns (Time and Speed)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process the first file as an example\n",
    "if data_files:\n",
    "    example_df = read_data_file(data_files[0])\n",
    "    print(\"\\nExample file structure:\")\n",
    "    print(example_df.info())\n",
    "    print(\"\\nSample of processed data:\")\n",
    "    print(example_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad02c",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1f0aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (534201, 3)\n",
      "\n",
      "Initial speed statistics:\n",
      "count    534201.000000\n",
      "mean          6.472042\n",
      "std           6.983279\n",
      "min         -40.070000\n",
      "25%           3.020000\n",
      "50%           5.080000\n",
      "75%           7.950000\n",
      "max         645.010000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Number of artifacts removed (speed > 100 cm/s): 99\n",
      "\n",
      "Speed statistics after removing artifacts:\n",
      "count    534102.000000\n",
      "mean          6.427781\n",
      "std           5.741578\n",
      "min         -40.070000\n",
      "25%           3.020000\n",
      "50%           5.080000\n",
      "75%           7.950000\n",
      "max          99.160000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Speed statistics after interpolation:\n",
      "count    534201.000000\n",
      "mean          6.439470\n",
      "std           5.815051\n",
      "min         -40.070000\n",
      "25%           3.020000\n",
      "50%           5.080000\n",
      "75%           7.950000\n",
      "max          99.160000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Number of events found: 1\n",
      "Event time points: [4982.6]\n",
      "\n",
      "Speed distribution percentiles:\n",
      "5th percentile: 0.78 cm/s\n",
      "25th percentile: 3.02 cm/s\n",
      "50th percentile: 5.08 cm/s\n",
      "75th percentile: 7.95 cm/s\n",
      "95th percentile: 16.93 cm/s\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "print(\"Original data shape:\", df.shape)\n",
    "\n",
    "# Convert speed column to numeric, handling any non-numeric values\n",
    "df_cleaned = df.copy()\n",
    "# Speed is always in column 1 (second column)\n",
    "df_cleaned.iloc[:, 1] = pd.to_numeric(df_cleaned.iloc[:, 1], errors='coerce')\n",
    "print(\"\\nInitial speed statistics:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Remove speed artifacts (>100 cm/s)\n",
    "artifacts_mask = df_cleaned.iloc[:, 1] > 100\n",
    "n_artifacts = artifacts_mask.sum()\n",
    "df_cleaned.iloc[artifacts_mask, 1] = np.nan  # Replace artifacts with NaN\n",
    "print(f\"\\nNumber of artifacts removed (speed > 100 cm/s): {n_artifacts}\")\n",
    "print(\"\\nSpeed statistics after removing artifacts:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Interpolate NaN values\n",
    "df_cleaned.iloc[:, 1] = df_cleaned.iloc[:, 1].interpolate(method='linear')\n",
    "print(\"\\nSpeed statistics after interpolation:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Verify event markers (using position-based indexing for consistency)\n",
    "event_times = df_cleaned[df_cleaned.iloc[:, 2] == 1].iloc[:, 0]  # Column 2 is Marker, Column 0 is Time\n",
    "print(f\"\\nNumber of events found: {len(event_times)}\")\n",
    "print(\"Event time points:\", event_times.values)\n",
    "\n",
    "# Calculate percentiles for speed distribution\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "speed_percentiles = np.percentile(df_cleaned.iloc[:, 1].dropna(), percentiles)\n",
    "print(\"\\nSpeed distribution percentiles:\")\n",
    "for p, v in zip(percentiles, speed_percentiles):\n",
    "    print(f\"{p}th percentile: {v:.2f} cm/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_locomotion_data(df, filename):\n",
    "    \"\"\"\n",
    "    Analyze locomotion data for a single file\n",
    "    \n",
    "    Parameters:\n",
    "    df : pandas DataFrame\n",
    "        Raw data with Time, Speed, and Marker columns\n",
    "    filename : str\n",
    "        Original filename for reporting\n",
    "        \n",
    "    Returns:\n",
    "    tuple : (df_cleaned, speed_results, distance_results, data_completeness)\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing file: {os.path.basename(filename)}\")\n",
    "    \n",
    "    # Data cleaning\n",
    "    print(\"Original data shape:\", df.shape)\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned.iloc[:, 1] = pd.to_numeric(df_cleaned.iloc[:, 1], errors='coerce')\n",
    "    \n",
    "    # Remove speed artifacts (>100 cm/s)\n",
    "    artifacts_mask = df_cleaned.iloc[:, 1] > 100\n",
    "    n_artifacts = artifacts_mask.sum()\n",
    "    df_cleaned.iloc[artifacts_mask, 1] = np.nan\n",
    "    print(f\"Number of artifacts removed (speed > 100 cm/s): {n_artifacts}\")\n",
    "    \n",
    "    # Interpolate NaN values\n",
    "    df_cleaned.iloc[:, 1] = df_cleaned.iloc[:, 1].interpolate(method='linear')\n",
    "    \n",
    "    # Find the event time\n",
    "    try:\n",
    "        event_markers = df_cleaned[df_cleaned.iloc[:, 2] == 1]\n",
    "        if len(event_markers) > 0:\n",
    "            event_time = event_markers.iloc[0, 0]\n",
    "            print(f\"Found event marker at time: {event_time:.2f} seconds\")\n",
    "        else:\n",
    "            time_min = df_cleaned.iloc[:, 0].min()\n",
    "            time_max = df_cleaned.iloc[:, 0].max()\n",
    "            event_time = (time_max + time_min) / 2\n",
    "            print(f\"No event markers found. Using middle point as event time: {event_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding event time: {str(e)}\")\n",
    "        time_min = df_cleaned.iloc[:, 0].min()\n",
    "        time_max = df_cleaned.iloc[:, 0].max()\n",
    "        event_time = (time_max + time_min) / 2\n",
    "        print(f\"Using middle point as event time: {event_time:.2f} seconds\")\n",
    "\n",
    "    # Rescale time relative to event (in hours)\n",
    "    df_cleaned['Time_hours'] = (df_cleaned.iloc[:, 0] - event_time) / 3600\n",
    "\n",
    "    # Define time windows (corrected to cumulative post-event windows)\n",
    "    time_windows = {\n",
    "        'pre_1h': (-1, 0),    # 1 hour before event\n",
    "        'post_1h': (0, 1),    # 0-1 hour after event\n",
    "        'post_2h': (0, 2),    # 0-2 hours after event\n",
    "        'post_3h': (0, 3)     # 0-3 hours after event\n",
    "    }\n",
    "    \n",
    "    # Calculate average speeds for each time window\n",
    "    speed_results = {}\n",
    "    data_completeness = {}\n",
    "    \n",
    "    for window_name, (start, end) in time_windows.items():\n",
    "        mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "        window_data = df_cleaned[mask]\n",
    "        \n",
    "        if len(window_data) > 0:\n",
    "            speed_results[window_name] = {\n",
    "                'mean_speed': window_data['Speed'].mean(),\n",
    "                'std_speed': window_data['Speed'].std(),\n",
    "                'n_points': len(window_data)\n",
    "            }\n",
    "            time_coverage = (window_data['Time_hours'].max() - window_data['Time_hours'].min()) * 60\n",
    "            data_completeness[window_name] = min(100, (time_coverage / 60) * 100)\n",
    "        else:\n",
    "            speed_results[window_name] = {\n",
    "                'mean_speed': np.nan,\n",
    "                'std_speed': np.nan,\n",
    "                'n_points': 0\n",
    "            }\n",
    "            data_completeness[window_name] = 0\n",
    "    \n",
    "    # Calculate distances\n",
    "    distance_results = {}\n",
    "    for window_name, (start, end) in time_windows.items():\n",
    "        mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "        window_data = df_cleaned[mask]\n",
    "        \n",
    "        if len(window_data) > 0:\n",
    "            speeds_cmh = window_data['Speed'] * 3600\n",
    "            time_diff_h = np.diff(window_data['Time_hours'])\n",
    "            speeds_for_calc = speeds_cmh[:-1]\n",
    "            \n",
    "            distance = np.sum(speeds_for_calc * time_diff_h)\n",
    "            \n",
    "            distance_results[window_name] = {\n",
    "                'distance_cm': distance,\n",
    "                'distance_m': distance / 100,\n",
    "                'completeness': data_completeness[window_name]\n",
    "            }\n",
    "        else:\n",
    "            distance_results[window_name] = {\n",
    "                'distance_cm': np.nan,\n",
    "                'distance_m': np.nan,\n",
    "                'completeness': 0\n",
    "            }\n",
    "    \n",
    "    return df_cleaned, speed_results, distance_results, data_completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25551c",
   "metadata": {},
   "source": [
    "## 3. Time Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea33eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found event marker at time: 4982.60 seconds\n",
      "\n",
      "Time range in dataset:\n",
      "Start: -1.38 hours\n",
      "End: 13.45 hours\n",
      "Total duration: 14.84 hours\n",
      "\n",
      "Data coverage in time windows:\n",
      "pre_1h: 35999 data points\n",
      "post_1h: 36000 data points\n",
      "post_2h: 36000 data points\n",
      "post_3h: 36000 data points\n"
     ]
    }
   ],
   "source": [
    "# Find the event time\n",
    "try:\n",
    "    # Using position-based indexing for consistency\n",
    "    event_markers = df_cleaned[df_cleaned.iloc[:, 2] == 1]\n",
    "    if len(event_markers) > 0:\n",
    "        event_time = event_markers.iloc[0, 0]  # Get time from first event marker\n",
    "        print(f\"Found event marker at time: {event_time:.2f} seconds\")\n",
    "    else:\n",
    "        # If no event markers found, use middle of the time range\n",
    "        time_min = df_cleaned.iloc[:, 0].min()\n",
    "        time_max = df_cleaned.iloc[:, 0].max()\n",
    "        event_time = (time_max + time_min) / 2\n",
    "        print(f\"No event markers found. Using middle point as event time: {event_time:.2f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Error finding event time: {str(e)}\")\n",
    "    # Default to middle of time range\n",
    "    time_min = df_cleaned.iloc[:, 0].min()\n",
    "    time_max = df_cleaned.iloc[:, 0].max()\n",
    "    event_time = (time_max + time_min) / 2\n",
    "    print(f\"Using middle point as event time: {event_time:.2f} seconds\")\n",
    "\n",
    "# Rescale time relative to event (in hours)\n",
    "df_cleaned['Time_hours'] = (df_cleaned.iloc[:, 0] - event_time) / 3600  # Convert to hours\n",
    "\n",
    "# Create time windows for analysis\n",
    "time_windows = {\n",
    "    'pre_1h': (-1, 0),\n",
    "    'post_1h': (0, 1),\n",
    "    'post_2h': (1, 2),\n",
    "    'post_3h': (2, 3)\n",
    "}\n",
    "\n",
    "# Print time range information\n",
    "print(\"\\nTime range in dataset:\")\n",
    "print(f\"Start: {df_cleaned['Time_hours'].min():.2f} hours\")\n",
    "print(f\"End: {df_cleaned['Time_hours'].max():.2f} hours\")\n",
    "print(f\"Total duration: {df_cleaned['Time_hours'].max() - df_cleaned['Time_hours'].min():.2f} hours\")\n",
    "\n",
    "# Print data points in each window\n",
    "print(\"\\nData coverage in time windows:\")\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    window_data = df_cleaned[(df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)]\n",
    "    print(f\"{window_name}: {len(window_data)} data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc2ec7",
   "metadata": {},
   "source": [
    "## 4. Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78263f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed Analysis Results:\n",
      "\n",
      "pre_1h:\n",
      "Mean Speed: 5.81 cm/s\n",
      "Std Dev: 3.91 cm/s\n",
      "Data Points: 35999\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_1h:\n",
      "Mean Speed: 2.32 cm/s\n",
      "Std Dev: 4.70 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_2h:\n",
      "Mean Speed: 4.37 cm/s\n",
      "Std Dev: 3.57 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_3h:\n",
      "Mean Speed: 6.17 cm/s\n",
      "Std Dev: 4.65 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate average speeds for each time window\n",
    "speed_results = {}\n",
    "data_completeness = {}\n",
    "\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "    window_data = df_cleaned[mask]\n",
    "    \n",
    "    if len(window_data) > 0:\n",
    "        speed_results[window_name] = {\n",
    "            'mean_speed': window_data['Speed'].mean(),\n",
    "            'std_speed': window_data['Speed'].std(),\n",
    "            'n_points': len(window_data)\n",
    "        }\n",
    "        # Calculate data completeness (percentage of the full hour covered)\n",
    "        time_coverage = (window_data['Time_hours'].max() - window_data['Time_hours'].min()) * 60  # in minutes\n",
    "        data_completeness[window_name] = min(100, (time_coverage / 60) * 100)  # as percentage of an hour\n",
    "    else:\n",
    "        speed_results[window_name] = {\n",
    "            'mean_speed': np.nan,\n",
    "            'std_speed': np.nan,\n",
    "            'n_points': 0\n",
    "        }\n",
    "        data_completeness[window_name] = 0\n",
    "\n",
    "# Print results\n",
    "print(\"Speed Analysis Results:\")\n",
    "for window, results in speed_results.items():\n",
    "    print(f\"\\n{window}:\")\n",
    "    print(f\"Mean Speed: {results['mean_speed']:.2f} cm/s\")\n",
    "    print(f\"Std Dev: {results['std_speed']:.2f} cm/s\")\n",
    "    print(f\"Data Points: {results['n_points']}\")\n",
    "    print(f\"Data Completeness: {data_completeness[window]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe225a",
   "metadata": {},
   "source": [
    "## 5. Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59934bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Analysis Results:\n",
      "\n",
      "pre_1h:\n",
      "Distance: 209.21 meters\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_1h:\n",
      "Distance: 83.67 meters\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_2h:\n",
      "Distance: 157.48 meters\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_3h:\n",
      "Distance: 221.97 meters\n",
      "Data Completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate distances for each time window\n",
    "distance_results = {}\n",
    "\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "    window_data = df_cleaned[mask]\n",
    "    \n",
    "    if len(window_data) > 0:\n",
    "        # Calculate distance by integrating speed over time\n",
    "        # Convert speed from cm/s to cm/h and time differences to hours\n",
    "        speeds_cmh = window_data['Speed'] * 3600  # convert to cm/h\n",
    "        time_diff_h = np.diff(window_data['Time_hours'])\n",
    "        speeds_for_calc = speeds_cmh[:-1]  # use speeds except last point\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = np.sum(speeds_for_calc * time_diff_h)\n",
    "        \n",
    "        distance_results[window_name] = {\n",
    "            'distance_cm': distance,\n",
    "            'distance_m': distance / 100,  # convert to meters\n",
    "            'completeness': data_completeness[window]\n",
    "        }\n",
    "    else:\n",
    "        distance_results[window_name] = {\n",
    "            'distance_cm': np.nan,\n",
    "            'distance_m': np.nan,\n",
    "            'completeness': 0\n",
    "        }\n",
    "\n",
    "# Print results\n",
    "print(\"Distance Analysis Results:\")\n",
    "for window, results in distance_results.items():\n",
    "    print(f\"\\n{window}:\")\n",
    "    print(f\"Distance: {results['distance_m']:.2f} meters\")\n",
    "    print(f\"Data Completeness: {results['completeness']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d502fcc",
   "metadata": {},
   "source": [
    "## 6. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6071ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,12.39,0\n",
      "0.1,10.70,0\n",
      "0.2,9.42,0\n",
      "0.3,8.57,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (417008, 3)\n",
      "\n",
      "Analyzing file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (417008, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 186\n",
      "Found event marker at time: 7109.10 seconds\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (417008, 3)\n",
      "\n",
      "Analyzing file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (417008, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 186\n",
      "Found event marker at time: 7109.10 seconds\n",
      "Results saved for C16_THC_0_1mpk\n",
      "\n",
      "Processing file: C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,7.213,0\n",
      "0.1,13.591,0\n",
      "0.2,18.463,0\n",
      "0.3,21.840,0\n",
      "Results saved for C16_THC_0_1mpk\n",
      "\n",
      "Processing file: C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,7.213,0\n",
      "0.1,13.591,0\n",
      "0.2,18.463,0\n",
      "0.3,21.840,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (406522, 3)\n",
      "\n",
      "Analyzing file: C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (406522, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 52\n",
      "Found event marker at time: 3935.40 seconds\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (406522, 3)\n",
      "\n",
      "Analyzing file: C16_THC_0_5mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (406522, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 52\n",
      "Found event marker at time: 3935.40 seconds\n",
      "Results saved for C16_THC_0_5mpk\n",
      "\n",
      "Processing file: C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,7.07,0\n",
      "0.1,7.02,0\n",
      "0.2,6.94,0\n",
      "0.3,6.84,0\n",
      "Results saved for C16_THC_0_5mpk\n",
      "\n",
      "Processing file: C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,7.07,0\n",
      "0.1,7.02,0\n",
      "0.2,6.94,0\n",
      "0.3,6.84,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (534201, 3)\n",
      "\n",
      "Analyzing file: C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (534201, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 99\n",
      "Found event marker at time: 4982.60 seconds\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (534201, 3)\n",
      "\n",
      "Analyzing file: C16_THC_2mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (534201, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 99\n",
      "Found event marker at time: 4982.60 seconds\n",
      "Results saved for C16_THC_2mpk\n",
      "\n",
      "Batch analysis complete!\n",
      "Results saved in: D:\\Temp\\DrugIntake behavior\\THC\\male\\test\\analysis_results\n",
      "Files processed: 3 out of 3\n",
      "\n",
      "Combined Summary (first few rows):\n",
      "             File  Total_Duration_hours  Pre_event_Duration_hours  Post_event_Duration_hours  Speed_Pre_1h  Speed_Post_1h  Speed_Post_2h  Speed_Post_3h  Distance_Pre_1h  Distance_Post_1h  Distance_Post_2h  Distance_Post_3h\n",
      "0  C16_THC_0_1mpk             11.583528                  1.974750                   9.608778      7.315757       7.348808       7.361364       7.679872       263.350475        264.547630        264.998260         276.47862\n",
      "1  C16_THC_0_5mpk             11.292250                  1.093167                  10.199083      8.623733      10.494561       8.489707       9.003674       310.435694        377.813067        305.615716         324.13093\n",
      "2    C16_THC_2mpk             14.838889                  1.384056                  13.454833      5.812017       2.324249       4.374564       6.165826       209.206830         83.670705        157.483450         221.96510\n",
      "Results saved for C16_THC_2mpk\n",
      "\n",
      "Batch analysis complete!\n",
      "Results saved in: D:\\Temp\\DrugIntake behavior\\THC\\male\\test\\analysis_results\n",
      "Files processed: 3 out of 3\n",
      "\n",
      "Combined Summary (first few rows):\n",
      "             File  Total_Duration_hours  Pre_event_Duration_hours  Post_event_Duration_hours  Speed_Pre_1h  Speed_Post_1h  Speed_Post_2h  Speed_Post_3h  Distance_Pre_1h  Distance_Post_1h  Distance_Post_2h  Distance_Post_3h\n",
      "0  C16_THC_0_1mpk             11.583528                  1.974750                   9.608778      7.315757       7.348808       7.361364       7.679872       263.350475        264.547630        264.998260         276.47862\n",
      "1  C16_THC_0_5mpk             11.292250                  1.093167                  10.199083      8.623733      10.494561       8.489707       9.003674       310.435694        377.813067        305.615716         324.13093\n",
      "2    C16_THC_2mpk             14.838889                  1.384056                  13.454833      5.812017       2.324249       4.374564       6.165826       209.206830         83.670705        157.483450         221.96510\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for batch analysis\n",
    "output_dir = os.path.join(folder_path, 'analysis_results')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process all files\n",
    "all_results = []\n",
    "\n",
    "for file_path in data_files:\n",
    "    try:\n",
    "        print(f\"\\nProcessing file: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Read and analyze the file\n",
    "        df = read_data_file(file_path)\n",
    "        df_cleaned, speed_results, distance_results, data_completeness = analyze_locomotion_data(df, file_path)\n",
    "        \n",
    "        # Clean up filename by removing \"_LocationOutput_TimeOverSpeed.txt\"\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        clean_name = base_name.replace(\"_LocationOutput_TimeOverSpeed\", \"\")\n",
    "        \n",
    "        # Create summary for this file as a single row\n",
    "        file_result = {\n",
    "            'File': clean_name,\n",
    "            'Total_Duration_hours': df_cleaned['Time_hours'].max() - df_cleaned['Time_hours'].min(),\n",
    "            'Pre_event_Duration_hours': abs(df_cleaned['Time_hours'].min()),\n",
    "            'Post_event_Duration_hours': df_cleaned['Time_hours'].max(),\n",
    "            'Speed_Pre_1h': speed_results['pre_1h']['mean_speed'],\n",
    "            'Speed_Post_1h': speed_results['post_1h']['mean_speed'],\n",
    "            'Speed_Post_2h': speed_results['post_2h']['mean_speed'],\n",
    "            'Speed_Post_3h': speed_results['post_3h']['mean_speed'],\n",
    "            'Distance_Pre_1h': distance_results['pre_1h']['distance_m'],\n",
    "            'Distance_Post_1h': distance_results['post_1h']['distance_m'],\n",
    "            'Distance_Post_2h': distance_results['post_2h']['distance_m'],\n",
    "            'Distance_Post_3h': distance_results['post_3h']['distance_m']\n",
    "        }\n",
    "        \n",
    "        # Save cleaned data (use original base_name for data files)\n",
    "        data_csv = os.path.join(output_dir, f\"{base_name}_data.csv\")\n",
    "        df_cleaned.to_csv(data_csv, index=False)\n",
    "        \n",
    "        # Add to all results\n",
    "        all_results.append(file_result)\n",
    "        \n",
    "        print(f\"Results saved for {clean_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {os.path.basename(file_path)}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create and save combined summary\n",
    "if all_results:\n",
    "    # Convert results to DataFrame (each file is a row)\n",
    "    combined_summary = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save combined summary\n",
    "    combined_csv = os.path.join(output_dir, \"combined_summary.csv\")\n",
    "    combined_summary.to_csv(combined_csv, index=False)\n",
    "    \n",
    "    print(f\"\\nBatch analysis complete!\")\n",
    "    print(f\"Results saved in: {output_dir}\")\n",
    "    print(f\"Files processed: {len(all_results)} out of {len(data_files)}\")\n",
    "    \n",
    "    # Display combined summary\n",
    "    print(\"\\nCombined Summary (first few rows):\")\n",
    "    print(combined_summary.head().to_string())\n",
    "else:\n",
    "    print(\"\\nNo files were successfully processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
