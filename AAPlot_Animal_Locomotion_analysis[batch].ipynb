{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c976d0",
   "metadata": {},
   "source": [
    "# 【AAPlot for Animal Behavior (Analyze)】\n",
    "## Extract speed and trajectory of **Spike2** exported .txt file\n",
    "\n",
    "This notebook analyzes animal movement data before and after specific events, including:\n",
    "- Data cleaning (removal of artifacts)\n",
    "- Time rescaling around events\n",
    "- Speed analysis in different time windows\n",
    "- Distance calculations\n",
    "- Statistical analysis and data export\n",
    "\n",
    "\n",
    "Run under `PLOT` environment\n",
    "    \n",
    "The `PLOT` enviorment：\n",
    "- Python3.12.7\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- ipykernel\n",
    "\n",
    "*Warning*\n",
    "\n",
    "*! Make sure you have installed `Anaconda`，and added to PATH（refering to internet）*\n",
    "\n",
    "*! Make sure you have already confiured the `PLOT` environment, if not, run this command: `conda env create -n PLOT python=3.12.7 pandas numpy matplotlib seaborn ipykernel` (If you are using ARM64 CPU, use Python3.13.3 intead，add `conda-forge` at the end of command)*\n",
    "\n",
    "*Apply `PLOT` in VScode ：Select in the Kernel*\n",
    "\n",
    "*Apply `PLOT` in terminal：`conda activate PLOT`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54d59c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "730c4829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\RuyiCai\\AppData\\Local\\Temp\\ipykernel_39592\\1143523068.py:36: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for separator in ['\\t', ',', '\\s+']:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 data files:\n",
      "- C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "- C17_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "- C19_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "- C93 0.1mpk.txt\n",
      "- C94 0.1mpk.txt\n",
      "- C95 0.1mpk.txt\n",
      "- C96 0.1mpk.txt\n",
      "\n",
      "Reading file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,12.39,0\n",
      "0.1,10.70,0\n",
      "0.2,9.42,0\n",
      "0.3,8.57,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (417008, 3)\n",
      "\n",
      "Example file structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417008 entries, 0 to 417007\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    417008 non-null  float64\n",
      " 1   Speed   417008 non-null  float64\n",
      " 2   Marker  417008 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.5 MB\n",
      "None\n",
      "\n",
      "Sample of processed data:\n",
      "   Time  Speed  Marker\n",
      "0   0.0  12.39       0\n",
      "1   0.1  10.70       0\n",
      "2   0.2   9.42       0\n",
      "3   0.3   8.57       0\n",
      "4   0.4   8.12       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import stats\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder selection - replace with your folder path\n",
    "folder_path = r'D:\\Temp\\DrugIntake behavior\\THC\\BatchAnalysis\\0.1'\n",
    "\n",
    "# Find all CSV and TXT files in the folder\n",
    "data_files = []\n",
    "for ext in ['.txt', '.csv']:\n",
    "    data_files.extend(glob.glob(os.path.join(folder_path, f'*{ext}')))\n",
    "\n",
    "if not data_files:\n",
    "    print(f\"No .txt or .csv files found in {folder_path}\")\n",
    "    raise ValueError(\"No data files found\")\n",
    "\n",
    "print(f\"Found {len(data_files)} data files:\")\n",
    "for file in data_files:\n",
    "    print(f\"- {os.path.basename(file)}\")\n",
    "\n",
    "# Function to read and preprocess a single file\n",
    "def read_data_file(filepath):\n",
    "    # First, look at the file structure\n",
    "    with open(filepath, 'r') as file:\n",
    "        first_few_lines = [next(file) for _ in range(5)]\n",
    "    print(f\"\\nReading file: {os.path.basename(filepath)}\")\n",
    "    print(\"First few lines:\")\n",
    "    for line in first_few_lines:\n",
    "        print(line.strip())\n",
    "    \n",
    "    # Try reading with different separators\n",
    "    for separator in ['\\t', ',', '\\s+']:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=separator, header=None, skiprows=1)\n",
    "            if len(df.columns) >= 2:  # We need at least time and speed columns\n",
    "                print(f\"Successfully read file with '{separator}' separator\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        raise ValueError(f\"Could not read file {filepath} with any known separator\")\n",
    "\n",
    "    print(\"Initial data shape:\", df.shape)\n",
    "    \n",
    "    # Convert time column to numeric\n",
    "    df.iloc[:, 0] = pd.to_numeric(df.iloc[:, 0], errors='coerce')\n",
    "    \n",
    "    # Rename columns by position\n",
    "    if len(df.columns) >= 3:\n",
    "        df = df.iloc[:, :3]  # Take only first three columns\n",
    "        df.columns = ['Time', 'Speed', 'Marker']\n",
    "    elif len(df.columns) == 2:\n",
    "        df = df.iloc[:, :2]  # Take only first two columns\n",
    "        df.columns = ['Time', 'Speed']\n",
    "        # Add marker column with default event at middle point\n",
    "        df['Marker'] = 0\n",
    "        middle_idx = len(df) // 2\n",
    "        df.loc[middle_idx, 'Marker'] = 1\n",
    "        print(\"No marker column found. Added marker at middle point.\")\n",
    "    else:\n",
    "        raise ValueError(\"File must have at least 2 columns (Time and Speed)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process the first file as an example\n",
    "if data_files:\n",
    "    example_df = read_data_file(data_files[0])\n",
    "    print(\"\\nExample file structure:\")\n",
    "    print(example_df.info())\n",
    "    print(\"\\nSample of processed data:\")\n",
    "    print(example_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad02c",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1f0aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (115590, 3)\n",
      "\n",
      "Initial speed statistics:\n",
      "count    115590.000000\n",
      "mean          7.437594\n",
      "std          12.189164\n",
      "min         -36.187000\n",
      "25%           2.186000\n",
      "50%           4.431000\n",
      "75%           8.372000\n",
      "max         311.414000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Number of artifacts removed (speed > 100 cm/s): 370\n",
      "\n",
      "Speed statistics after removing artifacts:\n",
      "count    115220.000000\n",
      "mean          6.973161\n",
      "std           8.729149\n",
      "min         -36.187000\n",
      "25%           2.186000\n",
      "50%           4.419000\n",
      "75%           8.312000\n",
      "max          99.545000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Speed statistics after interpolation:\n",
      "count    115590.000000\n",
      "mean          7.215625\n",
      "std           9.728024\n",
      "min         -36.187000\n",
      "25%           2.186000\n",
      "50%           4.431000\n",
      "75%           8.372000\n",
      "max          99.545000\n",
      "Name: Speed, dtype: float64\n",
      "\n",
      "Number of events found: 1\n",
      "Event time points: [3149.2]\n",
      "\n",
      "Speed distribution percentiles:\n",
      "5th percentile: 0.90 cm/s\n",
      "25th percentile: 2.19 cm/s\n",
      "50th percentile: 4.43 cm/s\n",
      "75th percentile: 8.37 cm/s\n",
      "95th percentile: 21.82 cm/s\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    # If df is not defined, use example_df from the previous cell\n",
    "    df = example_df\n",
    "print(\"Original data shape:\", df.shape)\n",
    "\n",
    "# Convert speed column to numeric, handling any non-numeric values\n",
    "df_cleaned = df.copy()\n",
    "# Speed is always in column 1 (second column)\n",
    "df_cleaned.iloc[:, 1] = pd.to_numeric(df_cleaned.iloc[:, 1], errors='coerce')\n",
    "print(\"\\nInitial speed statistics:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Remove speed artifacts (>100 cm/s)\n",
    "artifacts_mask = df_cleaned.iloc[:, 1] > 100\n",
    "n_artifacts = artifacts_mask.sum()\n",
    "df_cleaned.iloc[artifacts_mask, 1] = np.nan  # Replace artifacts with NaN\n",
    "print(f\"\\nNumber of artifacts removed (speed > 100 cm/s): {n_artifacts}\")\n",
    "print(\"\\nSpeed statistics after removing artifacts:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Interpolate NaN values\n",
    "df_cleaned.iloc[:, 1] = df_cleaned.iloc[:, 1].interpolate(method='linear')\n",
    "print(\"\\nSpeed statistics after interpolation:\")\n",
    "print(df_cleaned.iloc[:, 1].describe())\n",
    "\n",
    "# Verify event markers (using position-based indexing for consistency)\n",
    "event_times = df_cleaned[df_cleaned.iloc[:, 2] == 1].iloc[:, 0]  # Column 2 is Marker, Column 0 is Time\n",
    "print(f\"\\nNumber of events found: {len(event_times)}\")\n",
    "print(\"Event time points:\", event_times.values)\n",
    "\n",
    "# Calculate percentiles for speed distribution\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "speed_percentiles = np.percentile(df_cleaned.iloc[:, 1].dropna(), percentiles)\n",
    "print(\"\\nSpeed distribution percentiles:\")\n",
    "for p, v in zip(percentiles, speed_percentiles):\n",
    "    print(f\"{p}th percentile: {v:.2f} cm/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75aa015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_locomotion_data(df, filename):\n",
    "    \"\"\"\n",
    "    Analyze locomotion data for a single file\n",
    "    \n",
    "    Parameters:\n",
    "    df : pandas DataFrame\n",
    "        Raw data with Time, Speed, and Marker columns\n",
    "    filename : str\n",
    "        Original filename for reporting\n",
    "        \n",
    "    Returns:\n",
    "    tuple : (df_cleaned, speed_results, distance_results, data_completeness)\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing file: {os.path.basename(filename)}\")\n",
    "    \n",
    "    # Data cleaning\n",
    "    print(\"Original data shape:\", df.shape)\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned.iloc[:, 1] = pd.to_numeric(df_cleaned.iloc[:, 1], errors='coerce')\n",
    "    \n",
    "    # Remove speed artifacts (>100 cm/s)\n",
    "    artifacts_mask = df_cleaned.iloc[:, 1] > 100\n",
    "    n_artifacts = artifacts_mask.sum()\n",
    "    df_cleaned.iloc[artifacts_mask, 1] = np.nan\n",
    "    print(f\"Number of artifacts removed (speed > 100 cm/s): {n_artifacts}\")\n",
    "    \n",
    "    # Interpolate NaN values\n",
    "    df_cleaned.iloc[:, 1] = df_cleaned.iloc[:, 1].interpolate(method='linear')\n",
    "    \n",
    "    # Find the event time\n",
    "    try:\n",
    "        event_markers = df_cleaned[df_cleaned.iloc[:, 2] == 1]\n",
    "        if len(event_markers) > 0:\n",
    "            event_time = event_markers.iloc[0, 0]\n",
    "            print(f\"Found event marker at time: {event_time:.2f} seconds\")\n",
    "        else:\n",
    "            time_min = df_cleaned.iloc[:, 0].min()\n",
    "            time_max = df_cleaned.iloc[:, 0].max()\n",
    "            event_time = (time_max + time_min) / 2\n",
    "            print(f\"No event markers found. Using middle point as event time: {event_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding event time: {str(e)}\")\n",
    "        time_min = df_cleaned.iloc[:, 0].min()\n",
    "        time_max = df_cleaned.iloc[:, 0].max()\n",
    "        event_time = (time_max + time_min) / 2\n",
    "        print(f\"Using middle point as event time: {event_time:.2f} seconds\")\n",
    "\n",
    "    # Rescale time relative to event (in hours)\n",
    "    df_cleaned['Time_hours'] = (df_cleaned.iloc[:, 0] - event_time) / 3600\n",
    "\n",
    "    # Define time windows (corrected to cumulative post-event windows)\n",
    "    time_windows = {\n",
    "        'pre_1h': (-1.1, -0.1),    # 1 hour before event\n",
    "        'post_1h': (0.1, 1.1),    # 0-1 hour after event\n",
    "        'post_2h': (0.1, 2.1),    # 0-2 hours after event\n",
    "        'post_3h': (0.1, 3.1)     # 0-3 hours after event\n",
    "    }\n",
    "    \n",
    "    # Calculate average speeds for each time window\n",
    "    speed_results = {}\n",
    "    data_completeness = {}\n",
    "    \n",
    "    for window_name, (start, end) in time_windows.items():\n",
    "        mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "        window_data = df_cleaned[mask]\n",
    "        \n",
    "        if len(window_data) > 0:\n",
    "            speed_results[window_name] = {\n",
    "                'mean_speed': window_data['Speed'].mean(),\n",
    "                'std_speed': window_data['Speed'].std(),\n",
    "                'n_points': len(window_data)\n",
    "            }\n",
    "            time_coverage = (window_data['Time_hours'].max() - window_data['Time_hours'].min()) * 60\n",
    "            data_completeness[window_name] = min(100, (time_coverage / 60) * 100)\n",
    "        else:\n",
    "            speed_results[window_name] = {\n",
    "                'mean_speed': np.nan,\n",
    "                'std_speed': np.nan,\n",
    "                'n_points': 0\n",
    "            }\n",
    "            data_completeness[window_name] = 0\n",
    "    \n",
    "    # Calculate distances\n",
    "    distance_results = {}\n",
    "    for window_name, (start, end) in time_windows.items():\n",
    "        mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "        window_data = df_cleaned[mask]\n",
    "        \n",
    "        if len(window_data) > 0:\n",
    "            speeds_cmh = window_data['Speed'] * 3600\n",
    "            time_diff_h = np.diff(window_data['Time_hours'])\n",
    "            speeds_for_calc = speeds_cmh[:-1]\n",
    "            \n",
    "            distance = np.sum(speeds_for_calc * time_diff_h)\n",
    "            \n",
    "            distance_results[window_name] = {\n",
    "                'distance_cm': distance,\n",
    "                'distance_m': distance / 100,\n",
    "                'completeness': data_completeness[window_name]\n",
    "            }\n",
    "        else:\n",
    "            distance_results[window_name] = {\n",
    "                'distance_cm': np.nan,\n",
    "                'distance_m': np.nan,\n",
    "                'completeness': 0\n",
    "            }\n",
    "    \n",
    "    return df_cleaned, speed_results, distance_results, data_completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25551c",
   "metadata": {},
   "source": [
    "## 3. Time Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea33eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found event marker at time: 3149.20 seconds\n",
      "\n",
      "Time range in dataset:\n",
      "Start: -0.87 hours\n",
      "End: 2.34 hours\n",
      "Total duration: 3.21 hours\n",
      "\n",
      "Data coverage in time windows:\n",
      "pre_1h: 31492 data points\n",
      "post_1h: 36000 data points\n",
      "post_2h: 36000 data points\n",
      "post_3h: 12098 data points\n"
     ]
    }
   ],
   "source": [
    "# Find the event time\n",
    "try:\n",
    "    # Using position-based indexing for consistency\n",
    "    event_markers = df_cleaned[df_cleaned.iloc[:, 2] == 1]\n",
    "    if len(event_markers) > 0:\n",
    "        event_time = event_markers.iloc[0, 0]  # Get time from first event marker\n",
    "        print(f\"Found event marker at time: {event_time:.2f} seconds\")\n",
    "    else:\n",
    "        # If no event markers found, use middle of the time range\n",
    "        time_min = df_cleaned.iloc[:, 0].min()\n",
    "        time_max = df_cleaned.iloc[:, 0].max()\n",
    "        event_time = (time_max + time_min) / 2\n",
    "        print(f\"No event markers found. Using middle point as event time: {event_time:.2f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Error finding event time: {str(e)}\")\n",
    "    # Default to middle of time range\n",
    "    time_min = df_cleaned.iloc[:, 0].min()\n",
    "    time_max = df_cleaned.iloc[:, 0].max()\n",
    "    event_time = (time_max + time_min) / 2\n",
    "    print(f\"Using middle point as event time: {event_time:.2f} seconds\")\n",
    "\n",
    "# Rescale time relative to event (in hours)\n",
    "df_cleaned['Time_hours'] = (df_cleaned.iloc[:, 0] - event_time) / 3600  # Convert to hours\n",
    "\n",
    "# Create time windows for analysis\n",
    "time_windows = {\n",
    "    'pre_1h': (-1, 0),\n",
    "    'post_1h': (0, 1),\n",
    "    'post_2h': (1, 2),\n",
    "    'post_3h': (2, 3)\n",
    "}\n",
    "\n",
    "# Print time range information\n",
    "print(\"\\nTime range in dataset:\")\n",
    "print(f\"Start: {df_cleaned['Time_hours'].min():.2f} hours\")\n",
    "print(f\"End: {df_cleaned['Time_hours'].max():.2f} hours\")\n",
    "print(f\"Total duration: {df_cleaned['Time_hours'].max() - df_cleaned['Time_hours'].min():.2f} hours\")\n",
    "\n",
    "# Print data points in each window\n",
    "print(\"\\nData coverage in time windows:\")\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    window_data = df_cleaned[(df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)]\n",
    "    print(f\"{window_name}: {len(window_data)} data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc2ec7",
   "metadata": {},
   "source": [
    "## 4. Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78263f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed Analysis Results:\n",
      "\n",
      "pre_1h:\n",
      "Mean Speed: 11.55 cm/s\n",
      "Std Dev: 13.05 cm/s\n",
      "Data Points: 31492\n",
      "Data Completeness: 87.5%\n",
      "\n",
      "post_1h:\n",
      "Mean Speed: 6.19 cm/s\n",
      "Std Dev: 6.56 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_2h:\n",
      "Mean Speed: 4.51 cm/s\n",
      "Std Dev: 3.75 cm/s\n",
      "Data Points: 36000\n",
      "Data Completeness: 100.0%\n",
      "\n",
      "post_3h:\n",
      "Mean Speed: 7.05 cm/s\n",
      "Std Dev: 14.74 cm/s\n",
      "Data Points: 12098\n",
      "Data Completeness: 33.6%\n"
     ]
    }
   ],
   "source": [
    "# Calculate average speeds for each time window\n",
    "speed_results = {}\n",
    "data_completeness = {}\n",
    "\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "    window_data = df_cleaned[mask]\n",
    "    \n",
    "    if len(window_data) > 0:\n",
    "        speed_results[window_name] = {\n",
    "            'mean_speed': window_data['Speed'].mean(),\n",
    "            'std_speed': window_data['Speed'].std(),\n",
    "            'n_points': len(window_data)\n",
    "        }\n",
    "        # Calculate data completeness (percentage of the full hour covered)\n",
    "        time_coverage = (window_data['Time_hours'].max() - window_data['Time_hours'].min()) * 60  # in minutes\n",
    "        data_completeness[window_name] = min(100, (time_coverage / 60) * 100)  # as percentage of an hour\n",
    "    else:\n",
    "        speed_results[window_name] = {\n",
    "            'mean_speed': np.nan,\n",
    "            'std_speed': np.nan,\n",
    "            'n_points': 0\n",
    "        }\n",
    "        data_completeness[window_name] = 0\n",
    "\n",
    "# Print results\n",
    "print(\"Speed Analysis Results:\")\n",
    "for window, results in speed_results.items():\n",
    "    print(f\"\\n{window}:\")\n",
    "    print(f\"Mean Speed: {results['mean_speed']:.2f} cm/s\")\n",
    "    print(f\"Std Dev: {results['std_speed']:.2f} cm/s\")\n",
    "    print(f\"Data Points: {results['n_points']}\")\n",
    "    print(f\"Data Completeness: {data_completeness[window]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe225a",
   "metadata": {},
   "source": [
    "## 5. Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59934bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Analysis Results:\n",
      "\n",
      "pre_1h:\n",
      "Distance: 363.53 meters\n",
      "Data Completeness: 33.6%\n",
      "\n",
      "post_1h:\n",
      "Distance: 222.73 meters\n",
      "Data Completeness: 33.6%\n",
      "\n",
      "post_2h:\n",
      "Distance: 162.44 meters\n",
      "Data Completeness: 33.6%\n",
      "\n",
      "post_3h:\n",
      "Distance: 85.19 meters\n",
      "Data Completeness: 33.6%\n"
     ]
    }
   ],
   "source": [
    "# Calculate distances for each time window\n",
    "distance_results = {}\n",
    "\n",
    "for window_name, (start, end) in time_windows.items():\n",
    "    mask = (df_cleaned['Time_hours'] >= start) & (df_cleaned['Time_hours'] < end)\n",
    "    window_data = df_cleaned[mask]\n",
    "    \n",
    "    if len(window_data) > 0:\n",
    "        # Calculate distance by integrating speed over time\n",
    "        # Convert speed from cm/s to cm/h and time differences to hours\n",
    "        speeds_cmh = window_data['Speed'] * 3600  # convert to cm/h\n",
    "        time_diff_h = np.diff(window_data['Time_hours'])\n",
    "        speeds_for_calc = speeds_cmh[:-1]  # use speeds except last point\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = np.sum(speeds_for_calc * time_diff_h)\n",
    "        \n",
    "        distance_results[window_name] = {\n",
    "            'distance_cm': distance,\n",
    "            'distance_m': distance / 100,  # convert to meters\n",
    "            'completeness': data_completeness[window]\n",
    "        }\n",
    "    else:\n",
    "        distance_results[window_name] = {\n",
    "            'distance_cm': np.nan,\n",
    "            'distance_m': np.nan,\n",
    "            'completeness': 0\n",
    "        }\n",
    "\n",
    "# Print results\n",
    "print(\"Distance Analysis Results:\")\n",
    "for window, results in distance_results.items():\n",
    "    print(f\"\\n{window}:\")\n",
    "    print(f\"Distance: {results['distance_m']:.2f} meters\")\n",
    "    print(f\"Data Completeness: {results['completeness']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d502fcc",
   "metadata": {},
   "source": [
    "## 6. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6071ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,12.39,0\n",
      "0.1,10.70,0\n",
      "0.2,9.42,0\n",
      "0.3,8.57,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (417008, 3)\n",
      "\n",
      "Analyzing file: C16_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (417008, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 186\n",
      "Found event marker at time: 7109.10 seconds\n",
      "Results saved for C16_THC_0_1mpk\n",
      "\n",
      "Processing file: C17_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C17_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,4.263,0\n",
      "0.1,6.686,0\n",
      "0.2,8.617,0\n",
      "0.3,10.057,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (401418, 3)\n",
      "\n",
      "Analyzing file: C17_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (401418, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 100\n",
      "Found event marker at time: 3887.90 seconds\n",
      "Results saved for C17_THC_0_1mpk\n",
      "\n",
      "Processing file: C19_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "\n",
      "Reading file: C19_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,0.788,0\n",
      "0.1,2.472,0\n",
      "0.2,3.941,0\n",
      "0.3,5.195,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (443062, 3)\n",
      "\n",
      "Analyzing file: C19_THC_0_1mpk_LocationOutput_TimeOverSpeed.txt\n",
      "Original data shape: (443062, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 46\n",
      "Found event marker at time: 4695.40 seconds\n",
      "Results saved for C19_THC_0_1mpk\n",
      "\n",
      "Processing file: C93 0.1mpk.txt\n",
      "\n",
      "Reading file: C93 0.1mpk.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,6.227,0\n",
      "0.1,6.050,0\n",
      "0.2,5.774,0\n",
      "0.3,5.380,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (116320, 3)\n",
      "\n",
      "Analyzing file: C93 0.1mpk.txt\n",
      "Original data shape: (116320, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 509\n",
      "Found event marker at time: 1982.60 seconds\n",
      "Results saved for C93 0.1mpk\n",
      "\n",
      "Processing file: C94 0.1mpk.txt\n",
      "\n",
      "Reading file: C94 0.1mpk.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,0.087,0\n",
      "0.1,9.123,0\n",
      "0.2,16.848,0\n",
      "0.3,23.264,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (116499, 3)\n",
      "\n",
      "Analyzing file: C94 0.1mpk.txt\n",
      "Original data shape: (116499, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 255\n",
      "Found event marker at time: 3103.10 seconds\n",
      "Results saved for C94 0.1mpk\n",
      "\n",
      "Processing file: C95 0.1mpk.txt\n",
      "\n",
      "Reading file: C95 0.1mpk.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,4.953,0\n",
      "0.1,13.485,0\n",
      "0.2,20.027,0\n",
      "0.3,24.580,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (123035, 3)\n",
      "\n",
      "Analyzing file: C95 0.1mpk.txt\n",
      "Original data shape: (123035, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 43\n",
      "Found event marker at time: 4020.50 seconds\n",
      "Results saved for C95 0.1mpk\n",
      "\n",
      "Processing file: C96 0.1mpk.txt\n",
      "\n",
      "Reading file: C96 0.1mpk.txt\n",
      "First few lines:\n",
      "\"Time\",\"2 Speed(cm/s)\",\"1 Channel 1\"\n",
      "0.0,20.470,0\n",
      "0.1,21.497,0\n",
      "0.2,22.489,0\n",
      "0.3,23.420,0\n",
      "Successfully read file with ',' separator\n",
      "Initial data shape: (115590, 3)\n",
      "\n",
      "Analyzing file: C96 0.1mpk.txt\n",
      "Original data shape: (115590, 3)\n",
      "Number of artifacts removed (speed > 100 cm/s): 370\n",
      "Found event marker at time: 3149.20 seconds\n",
      "Results saved for C96 0.1mpk\n",
      "\n",
      "Batch analysis complete!\n",
      "Results saved in: D:\\Temp\\DrugIntake behavior\\THC\\BatchAnalysis\\0.1\\analysis_results\n",
      "Files processed: 7 out of 7\n",
      "\n",
      "Combined Summary (first few rows):\n",
      "             File  Total_Duration_hours  Pre_event_Duration_hours  Post_event_Duration_hours  Speed_Pre_1h  Speed_Post_1h  Speed_Post_2h  Speed_Post_3h  Distance_Pre_1h  Distance_Post_1h  Distance_Post_2h  Distance_Post_3h\n",
      "0  C16_THC_0_1mpk             11.583528                  1.974750                   9.608778      7.136592       7.443066       7.488338       7.500346       256.913780        267.945950        539.155510        810.035600\n",
      "1  C17_THC_0_1mpk             11.150472                  1.079972                  10.070500      7.299782       4.553145       4.252518       3.473797       257.523608        163.902761        306.174855        375.165285\n",
      "2  C19_THC_0_1mpk             12.307250                  1.304278                  11.002972      4.468764       2.578727       2.192524       2.001453       160.874397         92.831140        157.860460        216.153923\n",
      "3      C93 0.1mpk              3.231083                  0.550722                   2.680361     10.489441       8.032590       7.794354       7.140457       170.194736        289.166197        561.189103        663.299509\n",
      "4      C94 0.1mpk              3.236056                  0.861972                   2.374083      7.545140       4.924287       4.270188       4.076659       206.967718        177.271574        307.453140        333.726997\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for batch analysis\n",
    "output_dir = os.path.join(folder_path, 'analysis_results')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process all files\n",
    "all_results = []\n",
    "\n",
    "for file_path in data_files:\n",
    "    try:\n",
    "        print(f\"\\nProcessing file: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Read and analyze the file\n",
    "        df = read_data_file(file_path)\n",
    "        df_cleaned, speed_results, distance_results, data_completeness = analyze_locomotion_data(df, file_path)\n",
    "        \n",
    "        # Clean up filename by removing \"_LocationOutput_TimeOverSpeed.txt\"\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        clean_name = base_name.replace(\"_LocationOutput_TimeOverSpeed\", \"\")\n",
    "        \n",
    "        # Create summary for this file as a single row\n",
    "        file_result = {\n",
    "            'File': clean_name,\n",
    "            'Total_Duration_hours': df_cleaned['Time_hours'].max() - df_cleaned['Time_hours'].min(),\n",
    "            'Pre_event_Duration_hours': abs(df_cleaned['Time_hours'].min()),\n",
    "            'Post_event_Duration_hours': df_cleaned['Time_hours'].max(),\n",
    "            'Speed_Pre_1h': speed_results['pre_1h']['mean_speed'],\n",
    "            'Speed_Post_1h': speed_results['post_1h']['mean_speed'],\n",
    "            'Speed_Post_2h': speed_results['post_2h']['mean_speed'],\n",
    "            'Speed_Post_3h': speed_results['post_3h']['mean_speed'],\n",
    "            'Distance_Pre_1h': distance_results['pre_1h']['distance_m'],\n",
    "            'Distance_Post_1h': distance_results['post_1h']['distance_m'],\n",
    "            'Distance_Post_2h': distance_results['post_2h']['distance_m'],\n",
    "            'Distance_Post_3h': distance_results['post_3h']['distance_m']\n",
    "        }\n",
    "        \n",
    "        # Save cleaned data (use original base_name for data files)\n",
    "        data_csv = os.path.join(output_dir, f\"{base_name}_data.csv\")\n",
    "        df_cleaned.to_csv(data_csv, index=False)\n",
    "        \n",
    "        # Add to all results\n",
    "        all_results.append(file_result)\n",
    "        \n",
    "        print(f\"Results saved for {clean_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {os.path.basename(file_path)}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create and save combined summary\n",
    "if all_results:\n",
    "    # Convert results to DataFrame (each file is a row)\n",
    "    combined_summary = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save combined summary\n",
    "    combined_csv = os.path.join(output_dir, \"combined_summary.csv\")\n",
    "    combined_summary.to_csv(combined_csv, index=False)\n",
    "    \n",
    "    print(f\"\\nBatch analysis complete!\")\n",
    "    print(f\"Results saved in: {output_dir}\")\n",
    "    print(f\"Files processed: {len(all_results)} out of {len(data_files)}\")\n",
    "    \n",
    "    # Display combined summary\n",
    "    print(\"\\nCombined Summary (first few rows):\")\n",
    "    print(combined_summary.head().to_string())\n",
    "else:\n",
    "    print(\"\\nNo files were successfully processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
